digraph {
	graph [size="27.3,27.3"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1786972644624 [label="
 (64, 6)" fillcolor=darkolivegreen1]
	1788704959952 [label=AddmmBackward0]
	1788704955968 -> 1788704959952
	1788703042896 [label="fc.bias
 (6)" fillcolor=lightblue]
	1788703042896 -> 1788704955968
	1788704955968 [label=AccumulateGrad]
	1788704956496 -> 1788704959952
	1788704956496 [label=GeluBackward0]
	1788704960864 -> 1788704956496
	1788704960864 [label=AddmmBackward0]
	1788704960720 -> 1788704960864
	1788718828432 [label="hl.bias
 (128)" fillcolor=lightblue]
	1788718828432 -> 1788704960720
	1788704960720 [label=AccumulateGrad]
	1788704964512 -> 1788704960864
	1788704964512 [label=CatBackward0]
	1788704957072 -> 1788704964512
	1788704957072 [label=TanhBackward0]
	1788704957648 -> 1788704957072
	1788704957648 [label=AddmmBackward0]
	1788704956688 -> 1788704957648
	1788705356112 [label="encoder.pooler.dense.bias
 (768)" fillcolor=lightblue]
	1788705356112 -> 1788704956688
	1788704956688 [label=AccumulateGrad]
	1788704956208 -> 1788704957648
	1788704956208 [label=SelectBackward0]
	1788704954912 -> 1788704956208
	1788704954912 [label=SliceBackward0]
	1788704960816 -> 1788704954912
	1788704960816 [label=NativeLayerNormBackward0]
	1788704958800 -> 1788704960816
	1788704958800 [label=AddBackward0]
	1788704957456 -> 1788704958800
	1788704957456 [label=ViewBackward0]
	1788704962976 -> 1788704957456
	1788704962976 [label=AddmmBackward0]
	1788704957312 -> 1788704962976
	1788705355344 [label="encoder.encoder.layer.11.output.dense.bias
 (768)" fillcolor=lightblue]
	1788705355344 -> 1788704957312
	1788704957312 [label=AccumulateGrad]
	1788704961344 -> 1788704962976
	1788704961344 [label=ViewBackward0]
	1788704957504 -> 1788704961344
	1788704957504 [label=GeluBackward0]
	1788704955872 -> 1788704957504
	1788704955872 [label=ViewBackward0]
	1788704957840 -> 1788704955872
	1788704957840 [label=AddmmBackward0]
	1788704956784 -> 1788704957840
	1788705355248 [label="encoder.encoder.layer.11.intermediate.dense.bias
 (3072)" fillcolor=lightblue]
	1788705355248 -> 1788704956784
	1788704956784 [label=AccumulateGrad]
	1788704955536 -> 1788704957840
	1788704955536 [label=ViewBackward0]
	1788704958752 -> 1788704955536
	1788704958752 [label=NativeLayerNormBackward0]
	1788704957696 -> 1788704958752
	1788704957696 [label=AddBackward0]
	1788704957264 -> 1788704957696
	1788704957264 [label=ViewBackward0]
	1788704956544 -> 1788704957264
	1788704956544 [label=AddmmBackward0]
	1788704955008 -> 1788704956544
	1788705354960 [label="encoder.encoder.layer.11.attention.output.dense.bias
 (768)" fillcolor=lightblue]
	1788705354960 -> 1788704955008
	1788704955008 [label=AccumulateGrad]
	1788704956400 -> 1788704956544
	1788704956400 [label=ViewBackward0]
	1788704960624 -> 1788704956400
	1788704960624 [label=ViewBackward0]
	1788704959376 -> 1788704960624
	1788704959376 [label=TransposeBackward0]
	1788704960480 -> 1788704959376
	1788704960480 [label=ScaledDotProductEfficientAttentionBackward0]
	1788704960192 -> 1788704960480
	1788704960192 [label=PermuteBackward0]
	1788704955392 -> 1788704960192
	1788704955392 [label=ViewBackward0]
	1788704963360 -> 1788704955392
	1788704963360 [label=ViewBackward0]
	1788704963696 -> 1788704963360
	1788704963696 [label=AddmmBackward0]
	1788704960576 -> 1788704963696
	1788705354096 [label="encoder.encoder.layer.11.attention.self.query.bias
 (768)" fillcolor=lightblue]
	1788705354096 -> 1788704960576
	1788704960576 [label=AccumulateGrad]
	1788704963744 -> 1788704963696
	1788704963744 [label=TBackward0]
	1788704963408 -> 1788704963744
	1788705353232 [label="encoder.encoder.layer.11.attention.self.query.weight
 (768, 768)" fillcolor=lightblue]
	1788705353232 -> 1788704963408
	1788704963408 [label=AccumulateGrad]
	1788704960000 -> 1788704960480
	1788704960000 [label=PermuteBackward0]
	1788704963648 -> 1788704960000
	1788704963648 [label=ViewBackward0]
	1788704960240 -> 1788704963648
	1788704960240 [label=ViewBackward0]
	1788704955776 -> 1788704960240
	1788704955776 [label=AddmmBackward0]
	1788704961584 -> 1788704955776
	1788705354480 [label="encoder.encoder.layer.11.attention.self.key.bias
 (768)" fillcolor=lightblue]
	1788705354480 -> 1788704961584
	1788704961584 [label=AccumulateGrad]
	1788704963552 -> 1788704955776
	1788704963552 [label=TBackward0]
	1788704961632 -> 1788704963552
	1788705354288 [label="encoder.encoder.layer.11.attention.self.key.weight
 (768, 768)" fillcolor=lightblue]
	1788705354288 -> 1788704961632
	1788704961632 [label=AccumulateGrad]
	1788704954288 -> 1788704960480
	1788704954288 [label=PermuteBackward0]
	1788704960048 -> 1788704954288
	1788704960048 [label=ViewBackward0]
	1788704955824 -> 1788704960048
	1788704955824 [label=ViewBackward0]
	1788704958176 -> 1788704955824
	1788704958176 [label=AddmmBackward0]
	1788704955680 -> 1788704958176
	1788705354672 [label="encoder.encoder.layer.11.attention.self.value.bias
 (768)" fillcolor=lightblue]
	1788705354672 -> 1788704955680
	1788704955680 [label=AccumulateGrad]
	1788704955632 -> 1788704958176
	1788704955632 [label=TBackward0]
	1788704961680 -> 1788704955632
	1788705354576 [label="encoder.encoder.layer.11.attention.self.value.weight
 (768, 768)" fillcolor=lightblue]
	1788705354576 -> 1788704961680
	1788704961680 [label=AccumulateGrad]
	1788704956160 -> 1788704956544
	1788704956160 [label=TBackward0]
	1788704959856 -> 1788704956160
	1788705354192 [label="encoder.encoder.layer.11.attention.output.dense.weight
 (768, 768)" fillcolor=lightblue]
	1788705354192 -> 1788704959856
	1788704959856 [label=AccumulateGrad]
	1788704954192 -> 1788704958752
	1788705355152 [label="encoder.encoder.layer.11.attention.output.LayerNorm.weight
 (768)" fillcolor=lightblue]
	1788705355152 -> 1788704954192
	1788704954192 [label=AccumulateGrad]
	1788704956736 -> 1788704958752
	1788705355056 [label="encoder.encoder.layer.11.attention.output.LayerNorm.bias
 (768)" fillcolor=lightblue]
	1788705355056 -> 1788704956736
	1788704956736 [label=AccumulateGrad]
	1788704957600 -> 1788704957840
	1788704957600 [label=TBackward0]
	1788704960768 -> 1788704957600
	1788705354384 [label="encoder.encoder.layer.11.intermediate.dense.weight
 (3072, 768)" fillcolor=lightblue]
	1788705354384 -> 1788704960768
	1788704960768 [label=AccumulateGrad]
	1788704964032 -> 1788704962976
	1788704964032 [label=TBackward0]
	1788704957792 -> 1788704964032
	1788705355440 [label="encoder.encoder.layer.11.output.dense.weight
 (768, 3072)" fillcolor=lightblue]
	1788705355440 -> 1788704957792
	1788704957792 [label=AccumulateGrad]
	1788704958752 -> 1788704958800
	1788704960912 -> 1788704960816
	1788705355536 [label="encoder.encoder.layer.11.output.LayerNorm.weight
 (768)" fillcolor=lightblue]
	1788705355536 -> 1788704960912
	1788704960912 [label=AccumulateGrad]
	1788704962160 -> 1788704960816
	1788705354864 [label="encoder.encoder.layer.11.output.LayerNorm.bias
 (768)" fillcolor=lightblue]
	1788705354864 -> 1788704962160
	1788704962160 [label=AccumulateGrad]
	1788704961056 -> 1788704957648
	1788704961056 [label=TBackward0]
	1788704954528 -> 1788704961056
	1788705356016 [label="encoder.pooler.dense.weight
 (768, 768)" fillcolor=lightblue]
	1788705356016 -> 1788704954528
	1788704954528 [label=AccumulateGrad]
	1788704958896 -> 1788704960864
	1788704958896 [label=TBackward0]
	1788704956928 -> 1788704958896
	1787894791248 [label="hl.weight
 (128, 775)" fillcolor=lightblue]
	1787894791248 -> 1788704956928
	1788704956928 [label=AccumulateGrad]
	1788704956448 -> 1788704959952
	1788704956448 [label=TBackward0]
	1788704955248 -> 1788704956448
	1788703043568 [label="fc.weight
 (6, 128)" fillcolor=lightblue]
	1788703043568 -> 1788704955248
	1788704955248 [label=AccumulateGrad]
	1788704959952 -> 1786972644624
}

{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12064883,"sourceType":"datasetVersion","datasetId":7594019},{"sourceId":12066431,"sourceType":"datasetVersion","datasetId":7594939}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":10184.775986,"end_time":"2025-05-22T00:32:39.512691","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-05-21T21:42:54.736705","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"046524952c52414a953e28ea14797df0":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0fada372b0594285a8fb500c1c7a8c76":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16543bf5605a4fd9af912f4fe2167962":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1b53cb11fb5c46708916c5e50b783a7a":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21d2068208ed47e596988bba32c557bb":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_2737af6122ea496e8018900c57bf3758","placeholder":"​","style":"IPY_MODEL_45134b5df86549ae9ae9c6d86675eb2d","tabbable":null,"tooltip":null,"value":"tokenizer_config.json: 100%"}},"225efd5f431b493f8108c59a0284bbf0":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"263f2d4c9e284caaad70ce131f32b3a0":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_8971fd890e904a1e8ef4f710450996b8","max":498818054,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6827c2cfa6f746b2a5d985348a05e079","tabbable":null,"tooltip":null,"value":498818054}},"2737af6122ea496e8018900c57bf3758":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29657eb755c749419787306a28e5bd6d":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_1b53cb11fb5c46708916c5e50b783a7a","placeholder":"​","style":"IPY_MODEL_a531662c4e6c49c6ab5b9dd57907ec5b","tabbable":null,"tooltip":null,"value":" 499M/499M [00:03&lt;00:00, 380MB/s]"}},"2c0c80a9bf15412dbac2c17620d2a0c4":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_7b190cf583014a87a2833461467c3aac","placeholder":"​","style":"IPY_MODEL_6b880b9f8e5744ab92a002a7ecf6085c","tabbable":null,"tooltip":null,"value":"merges.txt: 100%"}},"3476a6609242490a93658158d9ae86d2":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3599bd71dbf2467784acd5aebdd46650":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_4801e873028245b99feb16233de59923","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_16543bf5605a4fd9af912f4fe2167962","tabbable":null,"tooltip":null,"value":481}},"35b7065e40b849658f8c2f493e79850c":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2c0c80a9bf15412dbac2c17620d2a0c4","IPY_MODEL_8767df641f774e7ba301446f33f0c731","IPY_MODEL_e44c326319dd481ebd7b952070dd525f"],"layout":"IPY_MODEL_0fada372b0594285a8fb500c1c7a8c76","tabbable":null,"tooltip":null}},"35f1ab7746ca4500ae93aa34a1ec0b5b":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_f4c68df84bc242df99bd6074dfc4b84d","placeholder":"​","style":"IPY_MODEL_67488af44e354f59869e7819909c4ed9","tabbable":null,"tooltip":null,"value":"model.safetensors: 100%"}},"3c6811cc8ff4495ab7b944859087b765":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45134b5df86549ae9ae9c6d86675eb2d":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"4801e873028245b99feb16233de59923":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50d990aa279843119b6af96660e8e5ec":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5df5b85cd53c4b9e996124eca4e90d2a":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"61a1a7e0863a467d8bb432f56017cb38":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"65c43bf9df854030b0570dbc7179c665":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"67488af44e354f59869e7819909c4ed9":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"6827c2cfa6f746b2a5d985348a05e079":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"692e734f23a14b9bab7eb8fee3f8e118":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"6b880b9f8e5744ab92a002a7ecf6085c":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"6eac57ba13d34f65bc27d3e4a2abdf56":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"71570ccb09fd4a2e92741f9597742e60":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"73fdaf54354e41d785c06d03ec19e6ca":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_8303bfe8914148a8a9bc7fe1091cb36b","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_65c43bf9df854030b0570dbc7179c665","tabbable":null,"tooltip":null,"value":898823}},"764ec2e45d3e42c4a323b8f7b0a5bba9":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9db0b0bcc1144ea6abacd991c268bc1b","IPY_MODEL_73fdaf54354e41d785c06d03ec19e6ca","IPY_MODEL_e289d5039f334ad6abba49538c060a6b"],"layout":"IPY_MODEL_d53bd9459c244907b83b5d15d9f6093a","tabbable":null,"tooltip":null}},"76b160eb0d2242cc81d72f98ff6820ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"795a9da9d089418b80c97d840df3368a":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7b190cf583014a87a2833461467c3aac":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8303bfe8914148a8a9bc7fe1091cb36b":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84f4654920f04cf0a3626f2279128143":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85389310ecac4782afec31a6acbb1d1d":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8767df641f774e7ba301446f33f0c731":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_3476a6609242490a93658158d9ae86d2","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_046524952c52414a953e28ea14797df0","tabbable":null,"tooltip":null,"value":456318}},"8971fd890e904a1e8ef4f710450996b8":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b102863fbb14cb3acfd943a8c4adbc9":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_bdc8ee195cd34c97bf5292af9b19d1f3","placeholder":"​","style":"IPY_MODEL_71570ccb09fd4a2e92741f9597742e60","tabbable":null,"tooltip":null,"value":" 1.36M/1.36M [00:00&lt;00:00, 6.81MB/s]"}},"8c3d098d572d43698fc4e89002914f87":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_21d2068208ed47e596988bba32c557bb","IPY_MODEL_bd7b64c36a8c485fa03725b05e2f326e","IPY_MODEL_c78413744e9644b398a1dd16b1287c16"],"layout":"IPY_MODEL_fb3e7627d1ec4a47ad6db0e18c7837e5","tabbable":null,"tooltip":null}},"92e85ad4b2ed494285a4abd059cb816e":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93d1f8ce5306497fb1db9e74aa7ab2e4":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_35f1ab7746ca4500ae93aa34a1ec0b5b","IPY_MODEL_263f2d4c9e284caaad70ce131f32b3a0","IPY_MODEL_29657eb755c749419787306a28e5bd6d"],"layout":"IPY_MODEL_50d990aa279843119b6af96660e8e5ec","tabbable":null,"tooltip":null}},"9db0b0bcc1144ea6abacd991c268bc1b":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_f97f727ab70d4a62a62be488f3a596a7","placeholder":"​","style":"IPY_MODEL_692e734f23a14b9bab7eb8fee3f8e118","tabbable":null,"tooltip":null,"value":"vocab.json: 100%"}},"a29e5121d0f84ea58d48a6f6f5604aa6":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3b551de986a4c54bcd3dcd7985b9526":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"a531662c4e6c49c6ab5b9dd57907ec5b":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"a57f8b0450994f5cb24a6c4f542953ce":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aaecbb98e57444fbae7880425eae63de":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b01778b9755c4216b0a273657ac0205c","IPY_MODEL_e1028cb5c4574a72bd290ac0c8dda5b3","IPY_MODEL_8b102863fbb14cb3acfd943a8c4adbc9"],"layout":"IPY_MODEL_84f4654920f04cf0a3626f2279128143","tabbable":null,"tooltip":null}},"b01778b9755c4216b0a273657ac0205c":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_92e85ad4b2ed494285a4abd059cb816e","placeholder":"​","style":"IPY_MODEL_5df5b85cd53c4b9e996124eca4e90d2a","tabbable":null,"tooltip":null,"value":"tokenizer.json: 100%"}},"b8a2143bbccd4c41bee0954b55599a1f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"bd7b64c36a8c485fa03725b05e2f326e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_a57f8b0450994f5cb24a6c4f542953ce","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_795a9da9d089418b80c97d840df3368a","tabbable":null,"tooltip":null,"value":25}},"bdc8ee195cd34c97bf5292af9b19d1f3":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c118d2a745414cf0a9f15576e697e45e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_f2f8e921c30e4b8baf8b879c9505af3d","placeholder":"​","style":"IPY_MODEL_61a1a7e0863a467d8bb432f56017cb38","tabbable":null,"tooltip":null,"value":"config.json: 100%"}},"c78413744e9644b398a1dd16b1287c16":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_225efd5f431b493f8108c59a0284bbf0","placeholder":"​","style":"IPY_MODEL_76b160eb0d2242cc81d72f98ff6820ab","tabbable":null,"tooltip":null,"value":" 25.0/25.0 [00:00&lt;00:00, 2.94kB/s]"}},"d53bd9459c244907b83b5d15d9f6093a":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d851e395e67d4b5cbf24a9bd8c94576c":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1028cb5c4574a72bd290ac0c8dda5b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_e95ff214456c4e44b6441ae04d081183","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6eac57ba13d34f65bc27d3e4a2abdf56","tabbable":null,"tooltip":null,"value":1355863}},"e289d5039f334ad6abba49538c060a6b":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_a29e5121d0f84ea58d48a6f6f5604aa6","placeholder":"​","style":"IPY_MODEL_eceda057bbc445438d92fbba34b394e6","tabbable":null,"tooltip":null,"value":" 899k/899k [00:00&lt;00:00, 4.39MB/s]"}},"e44c326319dd481ebd7b952070dd525f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_85389310ecac4782afec31a6acbb1d1d","placeholder":"​","style":"IPY_MODEL_b8a2143bbccd4c41bee0954b55599a1f","tabbable":null,"tooltip":null,"value":" 456k/456k [00:00&lt;00:00, 30.5MB/s]"}},"e95ff214456c4e44b6441ae04d081183":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eceda057bbc445438d92fbba34b394e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"f2f8e921c30e4b8baf8b879c9505af3d":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4c68df84bc242df99bd6074dfc4b84d":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f97f727ab70d4a62a62be488f3a596a7":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"faad4e8484434c7591aba00cb22e5680":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c118d2a745414cf0a9f15576e697e45e","IPY_MODEL_3599bd71dbf2467784acd5aebdd46650","IPY_MODEL_ff5a5f0d0c0c4cf2b8516198f4c4182b"],"layout":"IPY_MODEL_d851e395e67d4b5cbf24a9bd8c94576c","tabbable":null,"tooltip":null}},"fb3e7627d1ec4a47ad6db0e18c7837e5":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff5a5f0d0c0c4cf2b8516198f4c4182b":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_3c6811cc8ff4495ab7b944859087b765","placeholder":"​","style":"IPY_MODEL_a3b551de986a4c54bcd3dcd7985b9526","tabbable":null,"tooltip":null,"value":" 481/481 [00:00&lt;00:00, 59.0kB/s]"}}},"version_major":2,"version_minor":0}}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"708d29cb","cell_type":"code","source":"!pip install mlflow","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":11.286648,"end_time":"2025-05-21T21:43:10.249800","exception":false,"start_time":"2025-05-21T21:42:58.963152","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T06:47:55.253728Z","iopub.execute_input":"2025-06-05T06:47:55.254090Z","iopub.status.idle":"2025-06-05T06:47:58.639971Z","shell.execute_reply.started":"2025-06-05T06:47:55.254065Z","shell.execute_reply":"2025-06-05T06:47:58.639237Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: mlflow in /usr/local/lib/python3.11/dist-packages (2.22.0)\nRequirement already satisfied: mlflow-skinny==2.22.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.22.0)\nRequirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.0)\nRequirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.6)\nRequirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.15.2)\nRequirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (7.1.0)\nRequirement already satisfied: graphene<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.4.3)\nRequirement already satisfied: gunicorn<24 in /usr/local/lib/python3.11/dist-packages (from mlflow) (23.0.0)\nRequirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.7)\nRequirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.7.2)\nRequirement already satisfied: numpy<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.26.4)\nRequirement already satisfied: pandas<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.2.3)\nRequirement already satisfied: pyarrow<20,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (19.0.1)\nRequirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.2.2)\nRequirement already satisfied: scipy<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.15.2)\nRequirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.40)\nRequirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (5.5.2)\nRequirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (8.1.8)\nRequirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (3.1.1)\nRequirement already satisfied: databricks-sdk<1,>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (0.55.0)\nRequirement already satisfied: fastapi<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (0.115.12)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (3.1.44)\nRequirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (8.6.1)\nRequirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (1.31.1)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (1.31.1)\nRequirement already satisfied: packaging<25 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (24.2)\nRequirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (3.20.3)\nRequirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (2.11.4)\nRequirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (6.0.2)\nRequirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (2.32.3)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (0.5.3)\nRequirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (4.13.2)\nRequirement already satisfied: uvicorn<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (0.34.3)\nRequirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\nRequirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker<8,>=4.0.0->mlflow) (2.4.0)\nRequirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.3)\nRequirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (2.2.0)\nRequirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (1.9.0)\nRequirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (3.2.6)\nRequirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (3.2.0)\nRequirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (2.9.0.post0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (3.0.9)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (1.5.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\nRequirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (2.40.1)\nRequirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi<1->mlflow-skinny==2.22.0->mlflow) (0.46.2)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.22.0->mlflow) (4.0.12)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.22.0->mlflow) (3.21.0)\nRequirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (1.2.18)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.52b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (0.52b1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (0.4.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.0->mlflow) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.0->mlflow) (3.10)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.0->mlflow) (2025.4.26)\nRequirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn<1->mlflow-skinny==2.22.0->mlflow) (0.14.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3->mlflow) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3->mlflow) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3->mlflow) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3->mlflow) (2024.2.0)\nRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (1.17.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.22.0->mlflow) (5.0.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (4.9.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3->mlflow) (2024.2.0)\nRequirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.0->mlflow) (4.9.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.0->mlflow) (1.3.1)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (0.6.1)\n","output_type":"stream"}],"execution_count":2},{"id":"f50993aa","cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, Subset\nfrom random import sample\nfrom torch.utils.data import DataLoader\nfrom transformers import RobertaModel, RobertaTokenizer\nfrom sklearn.utils import resample\nfrom torchmetrics.classification import (\n    MulticlassF1Score,\n    MulticlassPrecision,\n    MulticlassRecall,\n)\nfrom tqdm import tqdm\nimport mlflow\nimport time\nimport pandas as pd\nimport os","metadata":{"papermill":{"duration":32.822203,"end_time":"2025-05-21T21:43:43.076166","exception":false,"start_time":"2025-05-21T21:43:10.253963","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T06:48:03.915428Z","iopub.execute_input":"2025-06-05T06:48:03.916127Z","iopub.status.idle":"2025-06-05T06:48:14.474594Z","shell.execute_reply.started":"2025-06-05T06:48:03.916095Z","shell.execute_reply":"2025-06-05T06:48:14.474000Z"}},"outputs":[{"name":"stderr","text":"2025-06-05 06:48:09.130929: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749106089.154565     121 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749106089.161527     121 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"id":"cde201fa","cell_type":"code","source":"LABEL_MAPPING = {\n    \"pants-fire\": 0,\n    \"false\": 1,\n    \"barely-true\": 2,\n    \"half-true\": 3,\n    \"mostly-true\": 4,\n    \"true\": 5,\n}\n\nids2labels = [\n    \"pants-fire\",\n    \"false\",\n    \"barely-true\",\n    \"half-true\",\n    \"mostly-true\",\n    \"true\",\n]\n\n\ndef save_checkpoint(model, optimizer, epoch, val_acc, path=\"checkpoint.pth\"):\n    checkpoint = {\n        \"model_state_dict\": model.state_for_save(),\n        \"optimizer_state_dict\": optimizer.state_dict(),\n        \"epoch\": epoch,\n        \"val_acc\": val_acc,\n    }\n    torch.save(checkpoint, path)\n    print(\n        f\"Checkpoint saved at epoch {epoch} \"\n        f\"with validation accuracy {val_acc:.4f}\"\n    )\n\n\ndef load_checkpoint(\n    model, optimizer, path=\"checkpoint.pth\", resume=False, reset_epoch=False\n):\n    if not resume:\n        print(\"Resume is False. Starting from scratch.\")\n        return 0, 0  # Start fresh\n\n    if os.path.exists(path):\n        checkpoint = torch.load(path)\n        model.load_state_from_save(checkpoint[\"model_state_dict\"])\n        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n        epoch = checkpoint[\"epoch\"]\n        val_acc = checkpoint[\"val_acc\"]\n        if reset_epoch:\n            print(\n                f\"Checkpoint loaded: Starting from initial\"\n                f\"epoch, validation accuracy {val_acc:.4f}\"\n            )\n            return 0, val_acc  # Start fresh with existing model\n        else:\n            print(\n                f\"Checkpoint loaded: Resuming from epoch \"\n                f\"{epoch+1}, validation accuracy {val_acc:.4f}\"\n            )\n            return epoch + 1, val_acc  # Next epoch to train\n    else:\n        print(\"No checkpoint found. Starting from scratch.\")\n        return 0, 0  # Start fresh\n\n\ndef save_best_model(model, optimizer, epoch, val_acc, path=\"best_model.pth\"):\n    best_model = {\n        \"model_state_dict\": model.state_for_save(),\n        \"optimizer_state_dict\": optimizer.state_dict(),\n        \"epoch\": epoch,\n        \"val_acc\": val_acc,\n    }\n    torch.save(best_model, path)\n    print(\n        f\"Best model saved at epoch {epoch} \"\n        f\"with validation accuracy {val_acc:.4f}\"\n    )\n\n\ndef load_best_model(model, path=\"best_model.pth\"):\n    if os.path.exists(path):\n        best_model = torch.load(path)\n        model.load_state_from_save(best_model[\"model_state_dict\"])\n        print(\"Model loaded from best model checkpoint.\")\n    else:\n        print(\"No best model checkpoint found.\")\n\ndef save_model_remotely(local_path, remote_path, creds):\n    pass\n","metadata":{"papermill":{"duration":0.022521,"end_time":"2025-05-21T21:43:43.102367","exception":false,"start_time":"2025-05-21T21:43:43.079846","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T06:48:17.686130Z","iopub.execute_input":"2025-06-05T06:48:17.687162Z","iopub.status.idle":"2025-06-05T06:48:17.695830Z","shell.execute_reply.started":"2025-06-05T06:48:17.687131Z","shell.execute_reply":"2025-06-05T06:48:17.695028Z"}},"outputs":[],"execution_count":4},{"id":"2946ca86","cell_type":"code","source":"class LiarPlusSingleRobertaDataset(Dataset):\n    def __init__(\n        self,\n        filepath: str,\n        tokenizer,\n        str_metadata_cols: list[str],\n        num_metadata_cols: list[str],\n        max_length: int = 512,\n    ):\n        self.df = pd.read_csv(filepath)\n\n        self.str_metadata_cols = str_metadata_cols\n        self.num_metadata_cols = num_metadata_cols\n\n        for column in self.str_metadata_cols:\n            self.df[column] = self.df[column].astype(str)\n\n        self.df[\"statement\"] = self.df[\"statement\"].astype(str)\n        self.df[\"justification\"] = self.df[\"justification\"].astype(str)\n        self.df[\"articles\"] = self.df[\"articles\"].astype(str)\n\n        self.statement_max_len = max_length // 4\n        self.justification_max_len = max_length // 4\n        self.article_max_len = max_length // 4\n        self.str_metadata_max_len = (\n            max_length - self.statement_max_len - self.justification_max_len - self.article_max_len\n        ) // len(str_metadata_cols)\n\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.df.index)\n\n    def limit_tokens(self, text, max_length=512):\n        tokenized = self.tokenizer.tokenize(text)[:max_length]\n        return self.tokenizer.decode(\n            self.tokenizer.convert_tokens_to_ids(tokenized)\n        )\n\n    def __getitem__(self, index: int):\n        item = self.df.iloc[index]\n\n        input = self.limit_tokens(\n            f\"[STATEMENT] {item['statement']}\", self.statement_max_len\n        )\n        input += self.limit_tokens(\n            f\" [JUSTIFICATION] {item['justification']}\",\n            self.justification_max_len,\n        )\n        input += self.limit_tokens(\n            f\" [ARTICLE] {item['articles']}\",\n            self.article_max_len,\n        )\n\n        for column in self.str_metadata_cols:\n            if column in [\"subject\", \"job_title\", \"context\", \"speaker\"]:\n                input += self.limit_tokens(f\" [{column.upper()}] {item[column]}\", 15)\n            else:\n                input += self.limit_tokens(f\" [{column.upper()}] {item[column]}\")\n\n        token_count = len(self.tokenizer.tokenize(input))\n        if token_count > self.max_length:\n            print(f\"Liczba tokenów przed kodowaniem: {token_count}\")\n            print(f\"Tekst: {input}\")\n\n        encoded = self.tokenizer(\n            input,\n            truncation=True,\n            padding=\"max_length\",\n            max_length=self.max_length,\n            return_tensors=\"pt\",\n        )\n\n        label = LABEL_MAPPING[item[\"label\"]]\n\n        num_metadata = [item[column] for column in self.num_metadata_cols]\n\n        return {\n            \"input_ids\": encoded[\"input_ids\"].squeeze(0),\n            \"attention_mask\": encoded[\"attention_mask\"].squeeze(0),\n            \"num_metadata\": torch.tensor(num_metadata).float(),\n            \"label\": torch.tensor(label),\n        }","metadata":{"papermill":{"duration":0.012512,"end_time":"2025-05-21T21:43:43.118040","exception":false,"start_time":"2025-05-21T21:43:43.105528","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T07:50:26.391251Z","iopub.execute_input":"2025-06-05T07:50:26.392050Z","iopub.status.idle":"2025-06-05T07:50:26.402263Z","shell.execute_reply.started":"2025-06-05T07:50:26.392021Z","shell.execute_reply":"2025-06-05T07:50:26.401536Z"}},"outputs":[],"execution_count":41},{"id":"a66840f3","cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass LiarPlusSingleFinetunedRoBERTasClassifier(nn.Module):\n    def __init__(\n        self, encoder_model, num_metadata_len, num_hidden, num_classes\n    ):\n        super(LiarPlusSingleFinetunedRoBERTasClassifier, self).__init__()\n        self.encoder = encoder_model\n        self.hl = nn.Linear(\n            self.encoder.config.hidden_size + num_metadata_len, num_hidden\n        )\n        self.dropout = nn.Dropout(p=0.1)\n        self.fc = nn.Linear(num_hidden, num_classes)\n\n    def forward(self, input_ids, attention_mask, num_metadata):\n        outputs = self.encoder(\n            input_ids=input_ids, attention_mask=attention_mask\n        )\n\n        cls_embedding = outputs.pooler_output\n        concatted_inputs = torch.cat([cls_embedding, num_metadata], dim=1)\n\n        hl_output = F.gelu(self.hl(concatted_inputs))\n        hl_output = self.dropout(hl_output)\n\n        logits = self.fc(hl_output)\n        return logits\n\n    def roberta_trainable_state(self):\n        return {\n            name: param for name, param in self.encoder.named_parameters() if param.requires_grad\n        }\n    \n    def load_roberta_trainable_state(self, state_dict):\n        self.encoder.load_state_dict(state_dict, strict=False)\n\n    # Zapisz tylko wagi warstw klasyfikatora\n    def state_for_save(self):\n        return {\n            'hl_state_dict': self.hl.state_dict(),\n            'fc_state_dict': self.fc.state_dict(),\n            'roberta_trainable': self.roberta_trainable_state(),\n        }\n        \n    # Ładowanie modelu (tylko wagi klasyfikatora)\n    def load_state_from_save(self, state):\n        self.hl.load_state_dict(state['hl_state_dict'])\n        self.fc.load_state_dict(state['fc_state_dict'])\n        if 'roberta_trainable' in state:\n            self.load_roberta_trainable_state(state['roberta_trainable'])","metadata":{"papermill":{"duration":0.011667,"end_time":"2025-05-21T21:43:43.132924","exception":false,"start_time":"2025-05-21T21:43:43.121257","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T06:48:36.795564Z","iopub.execute_input":"2025-06-05T06:48:36.796227Z","iopub.status.idle":"2025-06-05T06:48:36.803756Z","shell.execute_reply.started":"2025-06-05T06:48:36.796200Z","shell.execute_reply":"2025-06-05T06:48:36.802907Z"}},"outputs":[],"execution_count":6},{"id":"3e0fbdcf","cell_type":"code","source":"def test(\n    model: nn.Module,\n    best_model_path: str,\n    dataloader: DataLoader\n) -> None:\n    # Define loss function\n    criterion = nn.CrossEntropyLoss()\n\n    load_best_model(model, best_model_path)\n    \n    model.eval()  # Set model to evaluation mode\n    total_loss = 0.0\n    total_correct = 0\n    total_samples = 0\n\n    f1 = MulticlassF1Score(num_classes, average=None).to(device)\n    precision = MulticlassPrecision(num_classes, average=None).to(device)\n    recall = MulticlassRecall(num_classes, average=None).to(device)\n\n    with torch.no_grad():\n        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            num_metadata = batch[\"num_metadata\"].to(device)\n            labels = batch[\"label\"].to(device)\n\n            outputs = model(input_ids, attention_mask, num_metadata)\n            loss = criterion(outputs, labels)\n            total_loss += loss.item() * input_ids.size(0)\n\n            preds = torch.argmax(outputs, dim=1)\n            total_correct += (preds == labels).sum().item()\n            total_samples += input_ids.size(0)\n\n            f1.update(preds, labels)\n            precision.update(preds, labels)\n            recall.update(preds, labels)\n\n    avg_loss = total_loss / total_samples\n    accuracy = total_correct / total_samples\n\n    f1_res = f1.compute()\n    precision_res = precision.compute()\n    recall_res = recall.compute()\n\n    mlflow.log_metric(\"test_acc\", accuracy)\n    mlflow.log_metric(\"test_loss\", accuracy)\n\n    for i in range(num_classes):\n        mlflow.log_metric(f\"test_f1_{ids2labels[i]}\", f1_res[i])\n        mlflow.log_metric(f\"test_precision_{ids2labels[i]}\", precision_res[i])\n        mlflow.log_metric(f\"test_recall_{ids2labels[i]}\", recall_res[i])\n    \n    macro_f1 = f1_res.mean()\n    macro_precision = precision_res.mean()\n    macro_recall = recall_res.mean()\n\n    mlflow.log_metric(\"test_f1\", macro_f1)\n    mlflow.log_metric(\"test_precision\", macro_precision)\n    mlflow.log_metric(\"test_recall\", macro_recall)\n\n    print(\n        f\"Test Loss: {avg_loss:.4f}, \"\n        f\"Test Accuracy: {accuracy:.4f}, \"\n        f\"Test F1: {f1_res} (marcro = {macro_f1:.4f}), \"\n        f\"Test Precision: {precision_res} (marcro = {macro_precision:.4f}), \"\n        f\"Test Recall: {recall_res} (marcro = {macro_recall:.4f}), \"\n    )","metadata":{"papermill":{"duration":0.013636,"end_time":"2025-05-21T21:43:43.149820","exception":false,"start_time":"2025-05-21T21:43:43.136184","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T06:48:39.494908Z","iopub.execute_input":"2025-06-05T06:48:39.495213Z","iopub.status.idle":"2025-06-05T06:48:39.504160Z","shell.execute_reply.started":"2025-06-05T06:48:39.495190Z","shell.execute_reply":"2025-06-05T06:48:39.503289Z"}},"outputs":[],"execution_count":7},{"id":"3b9f5454","cell_type":"code","source":"def train(\n    creds: dict,\n    model: nn.Module,\n    save_path: str,\n    remote_models_path: str,\n    best_model_path: str,\n    train_loader: DataLoader,\n    val_loader: DataLoader,\n    test_loader: DataLoader,\n    batch_size: int,\n    num_classes: int,\n    lr=1e-3,\n    encoder_lr=1e-5,\n    epochs=30,\n    patience=5,\n    resume: bool = False,\n    reset_epoch: bool = False,\n) -> None:\n    dev_name = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    print(f\"Using device {dev_name}\")\n    device = torch.device(dev_name)\n\n    # Define optimizer and loss function\n    # Train only the classifier\n    optimizer = torch.optim.AdamW([\n        {'params': model.encoder.parameters(), 'lr': encoder_lr},  # niższe LR dla encodera\n        {'params': model.hl.parameters(), 'lr': lr},\n        {'params': model.fc.parameters(), 'lr': lr},\n    ])\n    criterion = nn.CrossEntropyLoss()\n\n    # Checkpoint Path\n    checkpoint_path = f\"checkpoint_{patience}.pth\"\n\n    checkpoint_send_interval = 5\n\n    # Track best loss for model saving\n    # Load Checkpoint (Decide if you want to continue)\n    start_epoch, best_val_accuracy = load_checkpoint(\n        model,\n        optimizer,\n        checkpoint_path,\n        resume,\n        reset_epoch\n    )\n\n    patience_counter = 0\n\n    f1 = MulticlassF1Score(num_classes, average=None).to(device)\n    precision = MulticlassPrecision(num_classes, average=None).to(device)\n    recall = MulticlassRecall(num_classes, average=None).to(device)\n\n    # Training loop\n    for epoch in range(start_epoch, epochs):\n        model.train()\n        epoch_loss = 0\n\n        train_accuracy = 0\n\n        for batch in tqdm(\n            train_loader, desc=f\"Epoch {epoch+1}\", leave=False\n        ):\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            num_metadata = batch[\"num_metadata\"].to(device)\n            labels = batch[\"label\"].to(device)\n\n            optimizer.zero_grad()\n            outputs = model(input_ids, attention_mask, num_metadata)\n            loss = criterion(\n                outputs, labels\n            )  # można spróbować to logować jako osobny wykres do debugowania\n            loss.backward()\n            optimizer.step()\n\n            epoch_loss += loss.item()\n\n            # Calculate accuracy\n            preds = torch.argmax(outputs, dim=-1)\n            train_accuracy += (preds == labels).sum().item()\n\n            f1.update(preds, labels)\n            precision.update(preds, labels)\n            recall.update(preds, labels)\n\n        avg_loss = epoch_loss / len(train_loader)\n        avg_train_accuracy = train_accuracy / len(train_loader.dataset)\n        mlflow.log_metric(\"train_loss\", avg_loss, step=epoch)\n        mlflow.log_metric(\"train_acc\", avg_train_accuracy, step=epoch)\n\n        f1_res = f1.compute()\n        precision_res = precision.compute()\n        recall_res = recall.compute()\n\n        for i in range(num_classes):\n            mlflow.log_metric(\n                f\"train_f1_{ids2labels[i]}\", f1_res[i], step=epoch\n            )\n            mlflow.log_metric(\n                f\"train_precision_{ids2labels[i]}\",\n                precision_res[i],\n                step=epoch,\n            )\n            mlflow.log_metric(\n                f\"train_recall_{ids2labels[i]}\", recall_res[i], step=epoch\n            )\n\n        macro_f1 = f1_res.mean()\n        macro_precision = precision_res.mean()\n        macro_recall = recall_res.mean()\n\n        mlflow.log_metric(\"train_f1\", macro_f1, step=epoch)\n        mlflow.log_metric(\"train_precision\", macro_precision, step=epoch)\n        mlflow.log_metric(\"train_recall\", macro_recall, step=epoch)\n\n        tqdm.write(\n            f\"Epoch {epoch+1}: \"\n            f\"Training Loss: {avg_loss}, \"\n            f\"Training Accuracy: {avg_train_accuracy}, \"\n            f\"Training F1: {macro_f1}, \"\n            f\"Training Precision: {macro_precision}, \"\n            f\"Training Recall: {macro_recall}\"\n        )\n\n        # Validation step\n        model.eval()  # Switch to evaluation mode\n        val_loss = 0\n        val_accuracy = 0\n\n        f1.reset()\n        precision.reset()\n        recall.reset()\n\n        with torch.no_grad():\n            for batch in tqdm(\n                val_loader,\n                desc=f\"Validation of epoch {epoch + 1}\",\n                leave=False,\n            ):\n                input_ids = batch[\"input_ids\"].to(device)\n                attention_mask = batch[\"attention_mask\"].to(device)\n                num_metadata = batch[\"num_metadata\"].to(device)\n                labels = batch[\"label\"].to(device)\n\n                outputs = model(input_ids, attention_mask, num_metadata)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n\n                # Calculate accuracy\n                preds = torch.argmax(outputs, dim=-1)\n                val_accuracy += (preds == labels).sum().item()\n                f1.update(preds, labels)\n                precision.update(preds, labels)\n                recall.update(preds, labels)\n\n        avg_val_loss = val_loss / len(val_loader)\n        avg_val_accuracy = val_accuracy / len(val_loader.dataset)\n        mlflow.log_metric(\"val_loss\", avg_val_loss, step=epoch)\n        mlflow.log_metric(\"val_acc\", avg_val_accuracy, step=epoch)\n\n        f1_res = f1.compute()\n        precision_res = precision.compute()\n        recall_res = recall.compute()\n\n        for i in range(num_classes):\n            mlflow.log_metric(\n                f\"val_f1_{ids2labels[i]}\", f1_res[i], step=epoch\n            )\n            mlflow.log_metric(\n                f\"val_precision_{ids2labels[i]}\",\n                precision_res[i],\n                step=epoch,\n            )\n            mlflow.log_metric(\n                f\"val_recall_{ids2labels[i]}\", recall_res[i], step=epoch\n            )\n\n        macro_f1 = f1_res.mean()\n        macro_precision = precision_res.mean()\n        macro_recall = recall_res.mean()\n\n        mlflow.log_metric(\"val_f1\", macro_f1, step=epoch)\n        mlflow.log_metric(\"val_precision\", macro_precision, step=epoch)\n        mlflow.log_metric(\"val_recall\", macro_recall, step=epoch)\n\n        print(\n            f\"Epoch {epoch+1}: \"\n            f\"Validation Loss: {avg_val_loss}, \"\n            f\"Validation Accuracy: {avg_val_accuracy}, \"\n            f\"Validation F1: {macro_f1}, \"\n            f\"Validation Precision: {macro_precision}, \"\n            f\"Validation Recall: {macro_recall}\"\n        )\n\n        save_checkpoint(\n            model, optimizer, epoch, avg_val_accuracy, checkpoint_path\n        )\n        if (epoch + 1) % checkpoint_send_interval == 0:# and epoch != 0:\n            save_model_remotely(checkpoint_path, remote_models_path, creds)\n\n        # Check for early stopping\n        if avg_val_accuracy > best_val_accuracy:\n            best_val_accuracy = avg_val_accuracy\n            patience_counter = 0\n            # Save the best model\n            save_best_model(\n                model,\n                optimizer,\n                epoch,\n                best_val_accuracy,\n                best_model_path\n            )\n            save_model_remotely(best_model_path, remote_models_path, creds)\n        else:\n            patience_counter += 1\n            if patience_counter >= patience:\n                print(f\"Early stopping at epoch {epoch+1}\")\n                break\n\n    # Log final checkpoint\n    save_model_remotely(checkpoint_path, remote_models_path, creds)","metadata":{"papermill":{"duration":0.022556,"end_time":"2025-05-21T21:43:43.175719","exception":false,"start_time":"2025-05-21T21:43:43.153163","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T06:48:42.817448Z","iopub.execute_input":"2025-06-05T06:48:42.818058Z","iopub.status.idle":"2025-06-05T06:48:42.835954Z","shell.execute_reply.started":"2025-06-05T06:48:42.818029Z","shell.execute_reply":"2025-06-05T06:48:42.835023Z"}},"outputs":[],"execution_count":8},{"id":"4f2e17af","cell_type":"code","source":"mlflow_uri = \"http://cimmerian.win:5000\"\nresume = False\nreset_epoch = False\n\ncreds = {\n    'hostname': \"cimmerian.win\",\n    'port': 22,\n    'username': \"\",\n    'password': \"\"\n}\n\nmlflow.set_tracking_uri(uri=mlflow_uri)\n\n# MLflow experiment setup\nmlflow.set_experiment(\"StatementMetadataJustificationArticle\")\n\n# Load RoBERTa tokenizer and model\ntokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\nroberta = RobertaModel.from_pretrained(\"roberta-base\")\n\n# trenuje 2 ostatnie warstwy\nfor name, param in roberta.named_parameters():\n    if name.startswith(\"encoder.layer.11\") or name.startswith(\"pooler\"):\n        param.requires_grad = True\n    else:\n        param.requires_grad = False\n\n\n# Hyperparameters\nnum_classes = 6\nlr = 1e-3\nencoder_lr = 1e-5\nepochs = 30\nhidden_size = 128\n# Number of epochs to wait before stopping if no improvement\npatience = 10\n\n# Save path\nsave_path = \"/kaggle/working\"\n# Remote models path\nremote_models_path = \"/home/conan/models/single_finetuned_roberta/\"\n# Best model path\nbest_model_path = f\"{save_path}/best_model_{patience}.pth\"\n\n# można przetestować zachłannie\n# dodajemy kolumnę jak poprawia i nie dodajemy jak nie poprawia\ntext_columns = [\n    \"subject\",\n    \"speaker\",\n    \"job_title\",\n    \"state\",\n    \"party_affiliation\",\n    \"context\",\n    \"sentiment\",\n    \"question\",\n    \"curse\",\n    \"emotion\",\n    \"gibberish\",\n    \"offensiveness\",\n    \"political_bias\"\n]\nnum_metadata_cols = [\n    \"barely_true_counts\",\n    \"false_counts\",\n    \"half_true_counts\",\n    \"mostly_true_counts\",\n    \"pants_on_fire_counts\",\n    \"grammar_errors\",\n    \"ratio_of_capital_letters\",\n    \"statement_length\"\n]\n\n#subset_size = 1000\n#random_state = 42\n\n# speedup the experiments\n# można ustawić epochs na 1 i sprawdzić czy w ramach jednej epoki val loss spada\ntraining_data = LiarPlusSingleRobertaDataset(\n    \"/kaggle/input/articles/train2.csv\",\n    tokenizer,\n    text_columns,\n    num_metadata_cols\n)\nvalidation_data = LiarPlusSingleRobertaDataset(\n    \"/kaggle/input/articles/val2.csv\",\n    tokenizer,\n    text_columns,\n    num_metadata_cols,\n)\ntest_data = LiarPlusSingleRobertaDataset(\n    \"/kaggle/input/articles/test2.csv\",\n    tokenizer,\n    text_columns,\n    num_metadata_cols,\n)\n\nbatch_size = 64\n\n#training_data_subset = Subset(training_data, sample(range(len(training_data)), k=1000))\n\ntrain_dataloader = DataLoader(\n    training_data, batch_size=batch_size, shuffle=True\n)\nval_dataloader = DataLoader(\n    validation_data, batch_size=batch_size, shuffle=True\n)\ntest_dataloader = DataLoader(\n    test_data, batch_size=batch_size, shuffle=True\n)\n\n# Instantiate model\nmodel = LiarPlusSingleFinetunedRoBERTasClassifier(\n    roberta,\n    len(num_metadata_cols),\n    hidden_size,\n    num_classes,\n)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\nstart = time.time()\nwith mlflow.start_run():\n    mlflow.log_param(\"learning_rate\", lr)\n    mlflow.log_param(\"batch_size\", batch_size)\n    mlflow.log_param(\"epochs\", epochs)\n    mlflow.log_param(\"resume\", resume)\n    mlflow.log_param(\"reset_epoch\", reset_epoch)\n    mlflow.log_param(\"patience\", patience)\n    \n    # Train the model\n    train(\n        creds,\n        model,\n        save_path,\n        remote_models_path,\n        best_model_path,\n        train_dataloader,\n        val_dataloader,\n        test_dataloader,\n        batch_size,\n        num_classes,\n        lr,\n        encoder_lr,\n        epochs,\n        patience,\n        resume,\n        reset_epoch,\n    )\n    # Evaluate on test dataset\n    test(model, best_model_path, test_dataloader)\nend = time.time()\nprint(f\"Total time took training: {end-start}s\")","metadata":{"papermill":{"duration":10132.633951,"end_time":"2025-05-22T00:32:35.812823","exception":false,"start_time":"2025-05-21T21:43:43.178872","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T07:53:32.964474Z","iopub.execute_input":"2025-06-05T07:53:32.965154Z"}},"outputs":[{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Using device cuda\nResume is False. Starting from scratch.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   0%|          | 0/161 [00:00<?, ?it/s]","output_type":"stream"}],"execution_count":null},{"id":"42f5a33a","cell_type":"code","source":"","metadata":{"papermill":{"duration":0.305088,"end_time":"2025-05-22T00:32:36.422689","exception":false,"start_time":"2025-05-22T00:32:36.117601","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null}]}
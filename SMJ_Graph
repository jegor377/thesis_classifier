digraph {
	graph [size="27.3,27.3"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2137986593232 [label="
 (64, 6)" fillcolor=darkolivegreen1]
	2137688320384 [label=AddmmBackward0]
	2137688325376 -> 2137688320384
	2137705630224 [label="fc.bias
 (6)" fillcolor=lightblue]
	2137705630224 -> 2137688325376
	2137688325376 [label=AccumulateGrad]
	2137688325808 -> 2137688320384
	2137688325808 [label=GeluBackward0]
	2137688323648 -> 2137688325808
	2137688323648 [label=AddmmBackward0]
	2137688322208 -> 2137688323648
	2137704582512 [label="hl.bias
 (128)" fillcolor=lightblue]
	2137704582512 -> 2137688322208
	2137688322208 [label=AccumulateGrad]
	2137688322064 -> 2137688323648
	2137688322064 [label=CatBackward0]
	2137688320576 -> 2137688322064
	2137688320576 [label=TanhBackward0]
	2137688322448 -> 2137688320576
	2137688322448 [label=AddmmBackward0]
	2137688325328 -> 2137688322448
	2137705628880 [label="encoder.pooler.dense.bias
 (768)" fillcolor=lightblue]
	2137705628880 -> 2137688325328
	2137688325328 [label=AccumulateGrad]
	2137688325856 -> 2137688322448
	2137688325856 [label=SelectBackward0]
	2137688323696 -> 2137688325856
	2137688323696 [label=SliceBackward0]
	2137688325616 -> 2137688323696
	2137688325616 [label=NativeLayerNormBackward0]
	2137688323072 -> 2137688325616
	2137688323072 [label=AddBackward0]
	2137688325184 -> 2137688323072
	2137688325184 [label=ViewBackward0]
	2137688322352 -> 2137688325184
	2137688322352 [label=AddmmBackward0]
	2137688323744 -> 2137688322352
	2137705628304 [label="encoder.encoder.layer.11.output.dense.bias
 (768)" fillcolor=lightblue]
	2137705628304 -> 2137688323744
	2137688323744 [label=AccumulateGrad]
	2137688325136 -> 2137688322352
	2137688325136 [label=ViewBackward0]
	2137688322400 -> 2137688325136
	2137688322400 [label=GeluBackward0]
	2137688463616 -> 2137688322400
	2137688463616 [label=ViewBackward0]
	2137688469808 -> 2137688463616
	2137688469808 [label=AddmmBackward0]
	2137688459632 -> 2137688469808
	2137714507024 [label="encoder.encoder.layer.11.intermediate.dense.bias
 (3072)" fillcolor=lightblue]
	2137714507024 -> 2137688459632
	2137688459632 [label=AccumulateGrad]
	2137688466832 -> 2137688469808
	2137688466832 [label=ViewBackward0]
	2137688321104 -> 2137688466832
	2137688321104 [label=NativeLayerNormBackward0]
	2137688464816 -> 2137688321104
	2137688464816 [label=AddBackward0]
	2137688463520 -> 2137688464816
	2137688463520 [label=ViewBackward0]
	2137688465008 -> 2137688463520
	2137688465008 [label=AddmmBackward0]
	2137688463328 -> 2137688465008
	2137714507600 [label="encoder.encoder.layer.11.attention.output.dense.bias
 (768)" fillcolor=lightblue]
	2137714507600 -> 2137688463328
	2137688463328 [label=AccumulateGrad]
	2137688462944 -> 2137688465008
	2137688462944 [label=ViewBackward0]
	2137688470144 -> 2137688462944
	2137688470144 [label=ViewBackward0]
	2137688463136 -> 2137688470144
	2137688463136 [label=TransposeBackward0]
	2137688463904 -> 2137688463136
	2137688463904 [label=ScaledDotProductEfficientAttentionBackward0]
	2137688469616 -> 2137688463904
	2137688469616 [label=PermuteBackward0]
	2137688463952 -> 2137688469616
	2137688463952 [label=ViewBackward0]
	2137688472448 -> 2137688463952
	2137688472448 [label=ViewBackward0]
	2137688467744 -> 2137688472448
	2137688467744 [label=AddmmBackward0]
	2137688464384 -> 2137688467744
	2137714506928 [label="encoder.encoder.layer.11.attention.self.query.bias
 (768)" fillcolor=lightblue]
	2137714506928 -> 2137688464384
	2137688464384 [label=AccumulateGrad]
	2137688468560 -> 2137688467744
	2137688468560 [label=TBackward0]
	2141104865344 -> 2137688468560
	2137714506064 [label="encoder.encoder.layer.11.attention.self.query.weight
 (768, 768)" fillcolor=lightblue]
	2137714506064 -> 2141104865344
	2141104865344 [label=AccumulateGrad]
	2137688469712 -> 2137688463904
	2137688469712 [label=PermuteBackward0]
	2137688464720 -> 2137688469712
	2137688464720 [label=ViewBackward0]
	2137688462800 -> 2137688464720
	2137688462800 [label=ViewBackward0]
	2141104865488 -> 2137688462800
	2141104865488 [label=AddmmBackward0]
	2141104865584 -> 2141104865488
	2137714507312 [label="encoder.encoder.layer.11.attention.self.key.bias
 (768)" fillcolor=lightblue]
	2137714507312 -> 2141104865584
	2141104865584 [label=AccumulateGrad]
	2141104865440 -> 2141104865488
	2141104865440 [label=TBackward0]
	2141104865632 -> 2141104865440
	2137714507120 [label="encoder.encoder.layer.11.attention.self.key.weight
 (768, 768)" fillcolor=lightblue]
	2137714507120 -> 2141104865632
	2141104865632 [label=AccumulateGrad]
	2137688459104 -> 2137688463904
	2137688459104 [label=PermuteBackward0]
	2137688465152 -> 2137688459104
	2137688465152 [label=ViewBackward0]
	2141104865680 -> 2137688465152
	2141104865680 [label=ViewBackward0]
	2141104865776 -> 2141104865680
	2141104865776 [label=AddmmBackward0]
	2141104865872 -> 2141104865776
	2137714507504 [label="encoder.encoder.layer.11.attention.self.value.bias
 (768)" fillcolor=lightblue]
	2137714507504 -> 2141104865872
	2141104865872 [label=AccumulateGrad]
	2141104865728 -> 2141104865776
	2141104865728 [label=TBackward0]
	2141104865920 -> 2141104865728
	2137714507408 [label="encoder.encoder.layer.11.attention.self.value.weight
 (768, 768)" fillcolor=lightblue]
	2137714507408 -> 2141104865920
	2141104865920 [label=AccumulateGrad]
	2137688471056 -> 2137688465008
	2137688471056 [label=TBackward0]
	2137688467216 -> 2137688471056
	2137705627728 [label="encoder.encoder.layer.11.attention.output.dense.weight
 (768, 768)" fillcolor=lightblue]
	2137705627728 -> 2137688467216
	2137688467216 [label=AccumulateGrad]
	2137688464432 -> 2137688321104
	2137705627920 [label="encoder.encoder.layer.11.attention.output.LayerNorm.weight
 (768)" fillcolor=lightblue]
	2137705627920 -> 2137688464432
	2137688464432 [label=AccumulateGrad]
	2137688464000 -> 2137688321104
	2137705627824 [label="encoder.encoder.layer.11.attention.output.LayerNorm.bias
 (768)" fillcolor=lightblue]
	2137705627824 -> 2137688464000
	2137688464000 [label=AccumulateGrad]
	2137688470192 -> 2137688469808
	2137688470192 [label=TBackward0]
	2137688467120 -> 2137688470192
	2137705628112 [label="encoder.encoder.layer.11.intermediate.dense.weight
 (3072, 768)" fillcolor=lightblue]
	2137705628112 -> 2137688467120
	2137688467120 [label=AccumulateGrad]
	2137688324944 -> 2137688322352
	2137688324944 [label=TBackward0]
	2137688463040 -> 2137688324944
	2137714507216 [label="encoder.encoder.layer.11.output.dense.weight
 (768, 3072)" fillcolor=lightblue]
	2137714507216 -> 2137688463040
	2137688463040 [label=AccumulateGrad]
	2137688321104 -> 2137688323072
	2137688322784 -> 2137688325616
	2137705628208 [label="encoder.encoder.layer.11.output.LayerNorm.weight
 (768)" fillcolor=lightblue]
	2137705628208 -> 2137688322784
	2137688322784 [label=AccumulateGrad]
	2137688322736 -> 2137688325616
	2137714507696 [label="encoder.encoder.layer.11.output.LayerNorm.bias
 (768)" fillcolor=lightblue]
	2137714507696 -> 2137688322736
	2137688322736 [label=AccumulateGrad]
	2137688322832 -> 2137688322448
	2137688322832 [label=TBackward0]
	2137688320816 -> 2137688322832
	2137705628784 [label="encoder.pooler.dense.weight
 (768, 768)" fillcolor=lightblue]
	2137705628784 -> 2137688320816
	2137688320816 [label=AccumulateGrad]
	2137688325520 -> 2137688323648
	2137688325520 [label=TBackward0]
	2137688323456 -> 2137688325520
	2137704582320 [label="hl.weight
 (128, 797)" fillcolor=lightblue]
	2137704582320 -> 2137688323456
	2137688323456 [label=AccumulateGrad]
	2137688325712 -> 2137688320384
	2137688325712 [label=TBackward0]
	2137688323984 -> 2137688325712
	2137701284752 [label="fc.weight
 (6, 128)" fillcolor=lightblue]
	2137701284752 -> 2137688323984
	2137688323984 [label=AccumulateGrad]
	2137688320384 -> 2137986593232
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6e32dd9-e5a8-485d-ab4b-20b0a2e56b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "from torchmetrics.classification import (\n",
    "    MulticlassF1Score,\n",
    "    MulticlassPrecision,\n",
    "    MulticlassRecall,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b50d36a8-9ebf-4e4b-b54b-da67b414212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import (\n",
    "    LABEL_MAPPING,\n",
    "    ids2labels,\n",
    "    save_checkpoint,\n",
    "    load_checkpoint,\n",
    "    save_best_model,\n",
    "    load_best_model,\n",
    "    save_model_remotely\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aea68431-6093-42b2-8251-1b5e96ca8a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_labels = {\n",
    "    \"sentiment\": ['negative', 'neutral', 'positive'],\n",
    "\t\"question\": ['not_question', 'question'],\n",
    "\t\"curse\": ['curse', 'non-curse'],\n",
    "\t\"emotion\": ['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise'],\n",
    "\t\"gibberish\": ['clean', 'mild gibberish', 'word salad'],\n",
    "\t\"offensiveness\": ['non-offensive', 'offensive'],\n",
    "\t\"political_bias\": ['CENTER', 'LEFT', 'RIGHT']\n",
    "}\n",
    "\n",
    "label_to_index = {\n",
    "    \"sentiment\": {label: idx for idx, label in enumerate(one_hot_labels[\"sentiment\"])},\n",
    "\t\"question\": {label: idx for idx, label in enumerate(one_hot_labels[\"question\"])},\n",
    "\t\"curse\": {label: idx for idx, label in enumerate(one_hot_labels[\"curse\"])},\n",
    "\t\"emotion\": {label: idx for idx, label in enumerate(one_hot_labels[\"emotion\"])},\n",
    "\t\"gibberish\": {label: idx for idx, label in enumerate(one_hot_labels[\"gibberish\"])},\n",
    "\t\"offensiveness\": {label: idx for idx, label in enumerate(one_hot_labels[\"offensiveness\"])},\n",
    "\t\"political_bias\": {label: idx for idx, label in enumerate(one_hot_labels[\"political_bias\"])}\n",
    "}\n",
    "\n",
    "one_hot_metadata_size = sum([len(x) for x in one_hot_labels.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8f3da8b-e341-4693-9338-47d85801a526",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LiarPlusSingleRobertaDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        filepath: str,\n",
    "        tokenizer,\n",
    "        str_metadata_cols: list[str],\n",
    "        num_metadata_cols: list[str],\n",
    "        one_hot_metadata_cols: list[str],\n",
    "        max_length: int = 512,\n",
    "    ):\n",
    "        self.df = pd.read_csv(filepath)\n",
    "\n",
    "        self.str_metadata_cols = str_metadata_cols\n",
    "        self.num_metadata_cols = num_metadata_cols\n",
    "        self.one_hot_metadata_cols = one_hot_metadata_cols\n",
    "\n",
    "        for column in self.str_metadata_cols:\n",
    "            self.df[column] = self.df[column].astype(str)\n",
    "\n",
    "        self.df[\"statement\"] = self.df[\"statement\"].astype(str)\n",
    "        self.df[\"justification\"] = self.df[\"justification\"].astype(str)\n",
    "        self.df[\"articles\"] = self.df[\"articles\"].astype(str)\n",
    "\n",
    "        self.statement_max_len = max_length // 4\n",
    "        self.justification_max_len = max_length // 4\n",
    "        self.article_max_len = max_length // 4\n",
    "        self.str_metadata_max_len = max((\n",
    "            max_length - self.statement_max_len - self.justification_max_len - self.article_max_len\n",
    "        ) // len(str_metadata_cols), 15)\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df.index)\n",
    "        \n",
    "    def limit_tokens(self, text, max_length=512):\n",
    "        return self.tokenizer.convert_tokens_to_string(\n",
    "            self.tokenizer.tokenize(text)[:max_length]\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        item = self.df.iloc[index]\n",
    "\n",
    "        input_text = self.limit_tokens(\n",
    "            f\"[STATEMENT] {item['statement']}\",\n",
    "            self.statement_max_len\n",
    "        )\n",
    "        input_text += self.limit_tokens(\n",
    "            f\" [JUSTIFICATION] {item['justification']}\",\n",
    "            self.justification_max_len,\n",
    "        )\n",
    "        input_text += self.limit_tokens(\n",
    "            f\" [ARTICLE] {item['articles']}\",\n",
    "            self.article_max_len,\n",
    "        )\n",
    "\n",
    "        for column in self.str_metadata_cols:\n",
    "            input_text += self.limit_tokens(f\" [{column.upper()}] {item[column]}\", self.str_metadata_max_len)\n",
    "\n",
    "        encoded = self.tokenizer(\n",
    "            input_text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        label = LABEL_MAPPING[item[\"label\"]]\n",
    "\n",
    "        num_metadata = [item[column] for column in self.num_metadata_cols]\n",
    "\n",
    "        one_hot_metadata = []\n",
    "        for column in self.one_hot_metadata_cols:\n",
    "            value = item[column]\n",
    "            possible_values = len(one_hot_labels[column])\n",
    "            id_tensor = torch.tensor(label_to_index[column][value])\n",
    "            one_hot_metadata.append(F.one_hot(id_tensor, possible_values))\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoded[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoded[\"attention_mask\"].squeeze(0),\n",
    "            \"num_metadata\": torch.tensor(num_metadata).float(),\n",
    "            \"one_hot_metadata\": torch.cat(one_hot_metadata, dim=0).float(),\n",
    "            \"label\": torch.tensor(label)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac266f37-607b-4e14-91fd-6ddba2eeb34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LiarPlusSingleFinetunedRoBERTasClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self, encoder_model, num_metadata_len, one_hot_metadata_size, num_hidden, num_classes\n",
    "    ):\n",
    "        super(LiarPlusSingleFinetunedRoBERTasClassifier, self).__init__()\n",
    "        self.encoder = encoder_model\n",
    "        self.hl = nn.Linear(\n",
    "            self.encoder.config.hidden_size + num_metadata_len + one_hot_metadata_size, num_hidden\n",
    "        )\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.fc = nn.Linear(num_hidden, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, num_metadata, one_hot_metadata):\n",
    "        outputs = self.encoder(\n",
    "            input_ids=input_ids, attention_mask=attention_mask\n",
    "        )\n",
    "\n",
    "        cls_embedding = outputs.pooler_output\n",
    "        concatted_inputs = torch.cat([cls_embedding, num_metadata, one_hot_metadata], dim=1)\n",
    "\n",
    "        hl_output = F.gelu(self.hl(concatted_inputs))\n",
    "        hl_output = self.dropout(hl_output)\n",
    "\n",
    "        logits = self.fc(hl_output)\n",
    "        return logits\n",
    "\n",
    "    def roberta_trainable_state(self):\n",
    "        return {\n",
    "            name: param for name, param in self.encoder.named_parameters() if param.requires_grad\n",
    "        }\n",
    "    \n",
    "    def load_roberta_trainable_state(self, state_dict):\n",
    "        self.encoder.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "    # Zapisz tylko wagi warstw klasyfikatora\n",
    "    def state_for_save(self):\n",
    "        return {\n",
    "            'hl_state_dict': self.hl.state_dict(),\n",
    "            'fc_state_dict': self.fc.state_dict(),\n",
    "            'roberta_trainable': self.roberta_trainable_state(),\n",
    "        }\n",
    "        \n",
    "    # Ładowanie modelu (tylko wagi klasyfikatora)\n",
    "    def load_state_from_save(self, state):\n",
    "        self.hl.load_state_dict(state['hl_state_dict'])\n",
    "        self.fc.load_state_dict(state['fc_state_dict'])\n",
    "        if 'roberta_trainable' in state:\n",
    "            self.load_roberta_trainable_state(state['roberta_trainable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1918be92-86fa-40ec-ac25-f941a97140f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(\n",
    "    model: nn.Module,\n",
    "    best_model_path: str,\n",
    "    dataloader: DataLoader,\n",
    "    name: str=\"Test\"\n",
    ") -> None:\n",
    "    # Define loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    load_best_model(model, best_model_path)\n",
    "    \n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    f1 = MulticlassF1Score(num_classes, average=None).to(device)\n",
    "    precision = MulticlassPrecision(num_classes, average=None).to(device)\n",
    "    recall = MulticlassRecall(num_classes, average=None).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            num_metadata = batch[\"num_metadata\"].to(device)\n",
    "            one_hot_metadata = batch[\"one_hot_metadata\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask, num_metadata, one_hot_metadata)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * input_ids.size(0)\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            total_correct += (preds == labels).sum().item()\n",
    "            total_samples += input_ids.size(0)\n",
    "\n",
    "            f1.update(preds, labels)\n",
    "            precision.update(preds, labels)\n",
    "            recall.update(preds, labels)\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    accuracy = total_correct / total_samples\n",
    "\n",
    "    f1_res = f1.compute()\n",
    "    precision_res = precision.compute()\n",
    "    recall_res = recall.compute()\n",
    "    \n",
    "    macro_f1 = f1_res.mean()\n",
    "    macro_precision = precision_res.mean()\n",
    "    macro_recall = recall_res.mean()\n",
    "\n",
    "    print(\n",
    "        f\"{name} Accuracy: {accuracy:.4f},\\n\"\n",
    "        f\"{name} Loss: {avg_loss:.4f},\\n\"\n",
    "        f\"{name} F1: {f1_res} (marcro = {macro_f1:.4f}),\\n\"\n",
    "        f\"{name} Precision: {precision_res} (marcro = {macro_precision:.4f}),\\n\"\n",
    "        f\"{name} Recall: {recall_res} (marcro = {macro_recall:.4f}),\\n\"\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        accuracy,\n",
    "        avg_loss,\n",
    "        macro_f1,\n",
    "        macro_precision,\n",
    "        macro_recall\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "992dc4de-c378-485e-8f9f-a61de08f6f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_classes = 6\n",
    "hidden_size = 128\n",
    "batch_size = 64\n",
    "\n",
    "text_columns = [\n",
    "    \"subject\",\n",
    "    \"speaker\",\n",
    "    \"job_title\",\n",
    "    \"state\",\n",
    "    \"party_affiliation\",\n",
    "    \"context\"\n",
    "]\n",
    "num_metadata_cols = [\n",
    "    \"barely_true_counts\",\n",
    "    \"false_counts\",\n",
    "    \"half_true_counts\",\n",
    "    \"mostly_true_counts\",\n",
    "    \"pants_on_fire_counts\",\n",
    "    \"grammar_errors\",\n",
    "    \"ratio_of_capital_letters\"\n",
    "]\n",
    "one_hot_cols = [\n",
    "    \"sentiment\",\n",
    "    \"question\",\n",
    "    \"curse\",\n",
    "    \"emotion\",\n",
    "    \"gibberish\",\n",
    "    \"offensiveness\",\n",
    "    \"political_bias\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "242a370d-86a9-4074-bbdc-c503bbf6d373",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "roberta = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# trenuje 2 ostatnie warstwy\n",
    "for name, param in roberta.named_parameters():\n",
    "    if name.startswith(\"encoder.layer.11\") or name.startswith(\"pooler\"):\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fd8457c-4414-494c-983d-76ad5c0ea9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = LiarPlusSingleRobertaDataset(\n",
    "    \"data/normalized/val2.csv\",\n",
    "    tokenizer,\n",
    "    text_columns,\n",
    "    num_metadata_cols,\n",
    "    one_hot_cols\n",
    ")\n",
    "test_data = LiarPlusSingleRobertaDataset(\n",
    "    \"data/normalized/test2.csv\",\n",
    "    tokenizer,\n",
    "    text_columns,\n",
    "    num_metadata_cols,\n",
    "    one_hot_cols\n",
    ")\n",
    "\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    validation_data, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_data, batch_size=batch_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f032f827-6c35-4dad-91bf-8a3e8c9fe577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LiarPlusSingleFinetunedRoBERTasClassifier(\n",
       "  (encoder): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (hl): Linear(in_features=797, out_features=128, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (fc): Linear(in_features=128, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LiarPlusSingleFinetunedRoBERTasClassifier(\n",
    "    roberta,\n",
    "    len(num_metadata_cols),\n",
    "    one_hot_metadata_size,\n",
    "    hidden_size,\n",
    "    num_classes,\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc9ae0cb-5c04-4ec2-99b7-d47693583d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from best model checkpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Studia\\nauka\\Sztuczna Inteligencja\\praca inżynierska\\klasyfikator\\utils.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model = torch.load(path)\n"
     ]
    }
   ],
   "source": [
    "best_model_path = \"results/FinalSMJA/best_model_6.pth\"\n",
    "load_best_model(model, best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51f8920e-c9f5-4de1-ace1-5bb12c37a0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from best model checkpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|                                                                               | 0/21 [00:00<?, ?it/s]E:\\anaconda3\\envs\\ML\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:370: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 21/21 [00:41<00:00,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.2931,\n",
      "Test Loss: 1.6299,\n",
      "Test F1: tensor([0.3562, 0.3657, 0.1538, 0.2954, 0.3508, 0.0429], device='cuda:0') (marcro = 0.2608),\n",
      "Test Precision: tensor([0.4815, 0.2870, 0.3056, 0.2814, 0.2843, 0.2273], device='cuda:0') (marcro = 0.3112),\n",
      "Test Recall: tensor([0.2826, 0.5040, 0.1028, 0.3109, 0.4578, 0.0237], device='cuda:0') (marcro = 0.2803),\n",
      "\n",
      "0.2930631332813718\n",
      "1.6298528739649711\n",
      "0.26080322265625\n",
      "0.3111618161201477\n",
      "0.2803003191947937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res = test(model, best_model_path, test_dataloader)\n",
    "print('\\n'.join([str(float(x)) for x in res]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c544df70-7f42-44f5-9bbf-18f7bd408b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from best model checkpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 21/21 [00:41<00:00,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3022,\n",
      "Validation Loss: 1.6261,\n",
      "Validation F1: tensor([0.4309, 0.3584, 0.1942, 0.2462, 0.3666, 0.0749], device='cuda:0') (marcro = 0.2785),\n",
      "Validation Precision: tensor([0.6000, 0.2890, 0.4167, 0.2321, 0.2929, 0.3889], device='cuda:0') (marcro = 0.3699),\n",
      "Validation Recall: tensor([0.3362, 0.4715, 0.1266, 0.2621, 0.4900, 0.0414], device='cuda:0') (marcro = 0.2880),\n",
      "\n",
      "0.30218068535825543\n",
      "1.626061411290154\n",
      "0.2785318195819855\n",
      "0.3699333369731903\n",
      "0.28797146677970886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res = test(model, best_model_path, val_dataloader, \"Validation\")\n",
    "print('\\n'.join([str(float(x)) for x in res]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aba475e0-9513-4edb-b819-841c59b1d437",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(test_dataloader))\n",
    "input_ids = batch[\"input_ids\"].to(device)\n",
    "attention_mask = batch[\"attention_mask\"].to(device)\n",
    "num_metadata = batch[\"num_metadata\"].to(device)\n",
    "one_hot_metadata = batch[\"one_hot_metadata\"].to(device)\n",
    "labels = batch[\"label\"].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36f118e6-deca-419d-859b-d0d08e922954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SMA_Graph.png'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(input_ids, attention_mask, num_metadata, one_hot_metadata)  # lub konkretnie np. loss\n",
    "make_dot(output, params=dict(model.named_parameters())).render(\"SMA_Graph\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9e26dd5-1bce-4d80-9776-c01e1bbcba6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from best model checkpoint.\n"
     ]
    }
   ],
   "source": [
    "best_model_path = \"results/FinalSMJA/best_model_10.pth\"\n",
    "load_best_model(model, best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c7c8b86-59b4-497d-aa30-4008240360c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from best model checkpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 21/21 [02:32<00:00,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.2993,\n",
      "Test Loss: 1.6489,\n",
      "Test F1: tensor([0.3590, 0.3179, 0.1846, 0.2934, 0.3400, 0.2954], device='cuda:0') (marcro = 0.2984),\n",
      "Test Precision: tensor([0.4375, 0.2871, 0.2703, 0.2808, 0.3092, 0.3020], device='cuda:0') (marcro = 0.3145),\n",
      "Test Recall: tensor([0.3043, 0.3560, 0.1402, 0.3071, 0.3775, 0.2891], device='cuda:0') (marcro = 0.2957),\n",
      "\n",
      "0.2992985190958691\n",
      "1.648909077547717\n",
      "0.29836520552635193\n",
      "0.3144799470901489\n",
      "0.2957100570201874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res = test(model, best_model_path, test_dataloader)\n",
    "print('\\n'.join([str(float(x)) for x in res]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47391810-9f1c-468d-83bc-0d1a78c76e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from best model checkpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 21/21 [02:31<00:00,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3146,\n",
      "Validation Loss: 1.6233,\n",
      "Validation F1: tensor([0.3979, 0.3580, 0.1925, 0.2904, 0.3321, 0.3196], device='cuda:0') (marcro = 0.3151),\n",
      "Validation Precision: tensor([0.5067, 0.3270, 0.3647, 0.2669, 0.3093, 0.2831], device='cuda:0') (marcro = 0.3429),\n",
      "Validation Recall: tensor([0.3276, 0.3954, 0.1308, 0.3185, 0.3586, 0.3669], device='cuda:0') (marcro = 0.3163),\n",
      "\n",
      "0.3146417445482866\n",
      "1.6232995615569974\n",
      "0.31509798765182495\n",
      "0.34294864535331726\n",
      "0.31630057096481323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res = test(model, best_model_path, val_dataloader, \"Validation\")\n",
    "print('\\n'.join([str(float(x)) for x in res]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

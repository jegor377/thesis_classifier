{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9ab38e8-f229-4490-973a-d68b5e99225c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a33cdcb3-1852-448c-8229-54395ad6f6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "roberta = RobertaModel.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86780e09-1f35-4569-bab8-3c35507c1833",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in roberta.parameters():\n",
    "    param.requires_grad = False  # Freeze all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f7b1e19-1e45-425f-b643-8310feeab32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "LABEL_MAPPING = {\n",
    "    \"pants-fire\": 0,\n",
    "    \"false\": 1,\n",
    "    \"barely-true\": 2,\n",
    "    \"half-true\": 3,\n",
    "    \"mostly-true\": 4,\n",
    "    \"true\": 5,\n",
    "}\n",
    "\n",
    "\n",
    "class LiarPlusStatementsDataset(Dataset):\n",
    "    def __init__(self, filepath: str, tokenizer, max_length: int = 128):\n",
    "        self.df = pd.read_csv(filepath, sep=\"\\t\")\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df.index)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        statement = self.df.iloc[index][\"statement\"]\n",
    "        label_str = self.df.iloc[index][\"label\"]\n",
    "\n",
    "        # Convert label to integer\n",
    "        label = LABEL_MAPPING[label_str]\n",
    "\n",
    "        # Tokenize the statement\n",
    "        encoding = self.tokenizer(\n",
    "            statement,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),  # Remove batch dim\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"label\": torch.tensor(label, dtype=torch.long),  # Ensure tensor\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b31d496-0896-4e8a-9f53-4c2dadfda1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = LiarPlusStatementsDataset(\"data/train2.tsv\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "147de9d9-d128-4501-b541-2a967870dc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    training_data, batch_size=batch_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c40d4c3-6151-4509-8601-22078fdd1369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class LiarPlusStatementsClassifier(nn.Module):\n",
    "    def __init__(self, encoder_model, num_classes):\n",
    "        super(LiarPlusStatementsClassifier, self).__init__()\n",
    "        self.encoder = encoder_model  # Pretrained encoder\n",
    "        self.fc = nn.Linear(\n",
    "            self.encoder.config.hidden_size, num_classes\n",
    "        )  # Custom classifier\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        with torch.no_grad():  # Ensure encoder remains frozen\n",
    "            outputs = self.encoder(\n",
    "                input_ids=input_ids, attention_mask=attention_mask\n",
    "            )\n",
    "        # Use [CLS] token output\n",
    "        cls_output = outputs.last_hidden_state[:, 0, :]\n",
    "        print(cls_output.shape)\n",
    "        logits = self.fc(cls_output)  # Pass through trainable classifier\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63e8ed32-07ab-4990-9354-245de2245a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b08af18-8423-426a-a8e9-ea4001d102b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LiarPlusStatementsClassifier(\n",
       "  (encoder): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LiarPlusStatementsClassifier(roberta, num_classes)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18b4249e-0bc0-4c05-bda0-aed11e22a05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "826c2028-e0c9-4169-8aec-149a21173f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0, 28084,     7,  ...,     1,     1,     1],\n",
       "         [    0,   104,  4113,  ...,     1,     1,     1],\n",
       "         [    0,  3972,   582,  ...,     1,     1,     1],\n",
       "         ...,\n",
       "         [    0,  1779,     5,  ...,     1,     1,     1],\n",
       "         [    0, 39254,  5141,  ...,     1,     1,     1],\n",
       "         [    0, 34053,  8279,  ...,     1,     1,     1]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'label': tensor([3, 2, 4, 1, 3, 1, 0, 0, 4, 1, 1, 4, 5, 1, 4, 2, 1, 1, 0, 2, 4, 3, 2, 3,\n",
       "         3, 3, 3, 4, 2, 1, 3, 4, 4, 5, 4, 1, 1, 4, 1, 2, 3, 3, 1, 4, 2, 4, 2, 4,\n",
       "         5, 2, 1, 1, 1, 3, 1, 5, 4, 5, 4, 3, 4, 5, 4, 1])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ab26afa-1b22-4bcf-8a67-6d693450ef71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 128])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80b15b43-b4bb-4bb6-85dc-6661c0277e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 128])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example['attention_mask'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5cd66a1-a417-41e6-8bc6-73e32ea8ed01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\envs\\ML\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:370: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 768])\n"
     ]
    }
   ],
   "source": [
    "res = model(input_ids=example['input_ids'].to(device), attention_mask=example['attention_mask'].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f878d1af-e2ab-4a6d-aca1-a3df42f4822d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 6])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d5cea03-a81f-499b-afb8-6893e3dacfb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0584,  0.3718,  0.2784,  0.1224, -0.2526, -0.0375],\n",
       "        [ 0.0589,  0.3739,  0.2665,  0.1146, -0.2365, -0.0486],\n",
       "        [ 0.0495,  0.3763,  0.2678,  0.1206, -0.2130, -0.0458],\n",
       "        [ 0.0569,  0.3656,  0.2750,  0.1211, -0.2257, -0.0303],\n",
       "        [ 0.0474,  0.3533,  0.3066,  0.1286, -0.2503, -0.0571],\n",
       "        [ 0.0558,  0.3500,  0.2638,  0.1218, -0.2552, -0.0616],\n",
       "        [ 0.0709,  0.3726,  0.2645,  0.0956, -0.2590, -0.0145],\n",
       "        [ 0.0699,  0.3549,  0.2939,  0.1410, -0.2526, -0.0527],\n",
       "        [ 0.0524,  0.3605,  0.2717,  0.1232, -0.2544, -0.0526],\n",
       "        [ 0.0689,  0.3620,  0.2627,  0.1083, -0.2256, -0.0381],\n",
       "        [ 0.0527,  0.3257,  0.2447,  0.1272, -0.2257, -0.0562],\n",
       "        [ 0.0484,  0.3380,  0.2562,  0.1222, -0.2131, -0.0460],\n",
       "        [ 0.0610,  0.3690,  0.2945,  0.1249, -0.2575, -0.0632],\n",
       "        [ 0.0697,  0.3474,  0.2856,  0.1104, -0.2246, -0.0450],\n",
       "        [ 0.0497,  0.3551,  0.2991,  0.1264, -0.2470, -0.0586],\n",
       "        [ 0.0598,  0.3488,  0.2849,  0.1144, -0.2088, -0.0626],\n",
       "        [ 0.0741,  0.3460,  0.2962,  0.1147, -0.2551, -0.0770],\n",
       "        [ 0.0663,  0.3501,  0.3040,  0.1206, -0.2362, -0.0531],\n",
       "        [ 0.0740,  0.3464,  0.2922,  0.1422, -0.2387, -0.0750],\n",
       "        [ 0.0671,  0.3783,  0.2753,  0.1241, -0.2512, -0.0419],\n",
       "        [ 0.0626,  0.3671,  0.2885,  0.1436, -0.2318, -0.0269],\n",
       "        [ 0.0803,  0.3535,  0.2876,  0.1011, -0.2210, -0.0312],\n",
       "        [ 0.0769,  0.3632,  0.2744,  0.0997, -0.2086, -0.0424],\n",
       "        [ 0.0527,  0.3600,  0.2562,  0.1240, -0.2548, -0.0584],\n",
       "        [ 0.0470,  0.3469,  0.2695,  0.1286, -0.2516, -0.0262],\n",
       "        [ 0.0705,  0.3509,  0.2812,  0.1450, -0.2272, -0.0286],\n",
       "        [ 0.0733,  0.3399,  0.2892,  0.1325, -0.1970, -0.0493],\n",
       "        [ 0.0447,  0.3496,  0.2870,  0.1227, -0.2506, -0.0575],\n",
       "        [ 0.0483,  0.3797,  0.2733,  0.1360, -0.2479, -0.0578],\n",
       "        [ 0.0626,  0.3390,  0.2861,  0.1215, -0.2637, -0.0541],\n",
       "        [ 0.0885,  0.3591,  0.2694,  0.1156, -0.2341, -0.0530],\n",
       "        [ 0.0454,  0.3424,  0.2899,  0.1274, -0.2553, -0.0601],\n",
       "        [ 0.0485,  0.3537,  0.2669,  0.0933, -0.2310, -0.0616],\n",
       "        [ 0.0707,  0.3682,  0.2766,  0.1106, -0.2546, -0.0153],\n",
       "        [ 0.0394,  0.3697,  0.2527,  0.1098, -0.2535, -0.0687],\n",
       "        [ 0.0361,  0.3461,  0.2810,  0.1152, -0.2348, -0.0334],\n",
       "        [ 0.0658,  0.3617,  0.2709,  0.1172, -0.2459, -0.0520],\n",
       "        [ 0.0880,  0.3588,  0.2820,  0.1121, -0.2575, -0.0903],\n",
       "        [ 0.0544,  0.3876,  0.3032,  0.1113, -0.2409, -0.0565],\n",
       "        [ 0.0692,  0.3440,  0.2993,  0.1130, -0.2347, -0.0732],\n",
       "        [ 0.0634,  0.3787,  0.2928,  0.1172, -0.2351, -0.0576],\n",
       "        [ 0.0654,  0.3443,  0.3000,  0.0904, -0.2307, -0.0521],\n",
       "        [ 0.0698,  0.3352,  0.2648,  0.1119, -0.2355, -0.0558],\n",
       "        [ 0.0609,  0.3606,  0.2708,  0.1179, -0.2742, -0.0498],\n",
       "        [ 0.0583,  0.3306,  0.2619,  0.1274, -0.2316, -0.0557],\n",
       "        [ 0.0575,  0.3369,  0.2803,  0.1166, -0.2462, -0.0596],\n",
       "        [ 0.0319,  0.3440,  0.2728,  0.1288, -0.2740, -0.0209],\n",
       "        [ 0.0532,  0.3474,  0.2536,  0.1139, -0.2464, -0.0345],\n",
       "        [ 0.0514,  0.3796,  0.2972,  0.1213, -0.2400, -0.0122],\n",
       "        [ 0.0767,  0.3405,  0.2832,  0.1356, -0.2252, -0.0665],\n",
       "        [ 0.0814,  0.3269,  0.3028,  0.1072, -0.2493, -0.0575],\n",
       "        [ 0.0560,  0.3657,  0.3092,  0.1318, -0.2279, -0.0525],\n",
       "        [ 0.0867,  0.3539,  0.2967,  0.1143, -0.2301, -0.0580],\n",
       "        [ 0.0448,  0.3647,  0.3037,  0.1345, -0.2703, -0.0616],\n",
       "        [ 0.0722,  0.3609,  0.2828,  0.1011, -0.2150, -0.0625],\n",
       "        [ 0.0552,  0.3473,  0.2428,  0.1357, -0.2408, -0.0514],\n",
       "        [ 0.0506,  0.3751,  0.2898,  0.1088, -0.2551, -0.0402],\n",
       "        [ 0.0520,  0.3687,  0.2805,  0.1073, -0.2536, -0.0330],\n",
       "        [ 0.0447,  0.3663,  0.2761,  0.1193, -0.2322, -0.0593],\n",
       "        [ 0.0467,  0.3574,  0.2721,  0.1281, -0.2459, -0.0531],\n",
       "        [ 0.0604,  0.3686,  0.2788,  0.1488, -0.2456, -0.0522],\n",
       "        [ 0.0610,  0.3184,  0.2989,  0.1133, -0.2351, -0.0560],\n",
       "        [ 0.0548,  0.3306,  0.3017,  0.1493, -0.2383, -0.0435],\n",
       "        [ 0.0448,  0.3739,  0.2745,  0.0998, -0.2393, -0.0471]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865d5e3e-9f68-419a-8f49-9443aa5aff58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6e32dd9-e5a8-485d-ab4b-20b0a2e56b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "from torchmetrics.classification import (\n",
    "    MulticlassF1Score,\n",
    "    MulticlassPrecision,\n",
    "    MulticlassRecall,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b50d36a8-9ebf-4e4b-b54b-da67b414212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import (\n",
    "    LABEL_MAPPING,\n",
    "    ids2labels,\n",
    "    save_checkpoint,\n",
    "    load_checkpoint,\n",
    "    save_best_model,\n",
    "    load_best_model,\n",
    "    save_model_remotely\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aea68431-6093-42b2-8251-1b5e96ca8a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_labels = {\n",
    "    \"sentiment\": ['negative', 'neutral', 'positive'],\n",
    "\t\"question\": ['not_question', 'question'],\n",
    "\t\"curse\": ['curse', 'non-curse'],\n",
    "\t\"emotion\": ['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise'],\n",
    "\t\"gibberish\": ['clean', 'mild gibberish', 'word salad'],\n",
    "\t\"offensiveness\": ['non-offensive', 'offensive'],\n",
    "\t\"political_bias\": ['CENTER', 'LEFT', 'RIGHT']\n",
    "}\n",
    "\n",
    "label_to_index = {\n",
    "    \"sentiment\": {label: idx for idx, label in enumerate(one_hot_labels[\"sentiment\"])},\n",
    "\t\"question\": {label: idx for idx, label in enumerate(one_hot_labels[\"question\"])},\n",
    "\t\"curse\": {label: idx for idx, label in enumerate(one_hot_labels[\"curse\"])},\n",
    "\t\"emotion\": {label: idx for idx, label in enumerate(one_hot_labels[\"emotion\"])},\n",
    "\t\"gibberish\": {label: idx for idx, label in enumerate(one_hot_labels[\"gibberish\"])},\n",
    "\t\"offensiveness\": {label: idx for idx, label in enumerate(one_hot_labels[\"offensiveness\"])},\n",
    "\t\"political_bias\": {label: idx for idx, label in enumerate(one_hot_labels[\"political_bias\"])}\n",
    "}\n",
    "\n",
    "one_hot_metadata_size = sum([len(x) for x in one_hot_labels.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8f3da8b-e341-4693-9338-47d85801a526",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LiarPlusSingleRobertaDataset_SM_And_SMA(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        filepath: str,\n",
    "        tokenizer,\n",
    "        str_metadata_cols: list[str],\n",
    "        num_metadata_cols: list[str],\n",
    "        one_hot_metadata_cols: list[str],\n",
    "        max_length: int = 512,\n",
    "    ):\n",
    "        self.df = pd.read_csv(filepath)\n",
    "\n",
    "        self.str_metadata_cols = str_metadata_cols\n",
    "        self.num_metadata_cols = num_metadata_cols\n",
    "        self.one_hot_metadata_cols = one_hot_metadata_cols\n",
    "\n",
    "        for column in self.str_metadata_cols:\n",
    "            self.df[column] = self.df[column].astype(str)\n",
    "\n",
    "        self.df[\"statement\"] = self.df[\"statement\"].astype(str)\n",
    "        self.df[\"articles\"] = self.df[\"articles\"].astype(str)\n",
    "\n",
    "        self.statement_max_len = max_length // 4\n",
    "        self.article_max_len = max_length // 4\n",
    "        self.str_metadata_max_len_SM = max((\n",
    "            max_length - self.statement_max_len\n",
    "        ) // len(str_metadata_cols), 15)\n",
    "        self.str_metadata_max_len_SMA = max((\n",
    "            max_length - self.statement_max_len - self.article_max_len\n",
    "        ) // len(str_metadata_cols), 15)\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df.index)\n",
    "        \n",
    "    def limit_tokens(self, text, max_length=512):\n",
    "        return self.tokenizer.convert_tokens_to_string(\n",
    "            self.tokenizer.tokenize(text)[:max_length]\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        item = self.df.iloc[index]\n",
    "\n",
    "        input_text_SM = self.limit_tokens(\n",
    "            f\"[STATEMENT] {item['statement']}\",\n",
    "            self.statement_max_len\n",
    "        )\n",
    "        \n",
    "        input_text_SMA = input_text_SM\n",
    "        input_text_SMA += self.limit_tokens(\n",
    "            f\" [ARTICLE] {item['articles']}\",\n",
    "            self.article_max_len,\n",
    "        )\n",
    "\n",
    "        for column in self.str_metadata_cols:\n",
    "            input_text_SM += self.limit_tokens(f\" [{column.upper()}] {item[column]}\", self.str_metadata_max_len_SM)\n",
    "            input_text_SMA += self.limit_tokens(f\" [{column.upper()}] {item[column]}\", self.str_metadata_max_len_SMA)\n",
    "\n",
    "        encoded_SM = self.tokenizer(\n",
    "            input_text_SM,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        encoded_SMA = self.tokenizer(\n",
    "            input_text_SMA,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        label = LABEL_MAPPING[item[\"label\"]]\n",
    "\n",
    "        num_metadata = [item[column] for column in self.num_metadata_cols]\n",
    "\n",
    "        one_hot_metadata = []\n",
    "        for column in self.one_hot_metadata_cols:\n",
    "            value = item[column]\n",
    "            possible_values = len(one_hot_labels[column])\n",
    "            id_tensor = torch.tensor(label_to_index[column][value])\n",
    "            one_hot_metadata.append(F.one_hot(id_tensor, possible_values))\n",
    "\n",
    "        return {\n",
    "            \"input_ids_SM\": encoded_SM[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask_SM\": encoded_SM[\"attention_mask\"].squeeze(0),\n",
    "            \"input_ids_SMA\": encoded_SMA[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask_SMA\": encoded_SMA[\"attention_mask\"].squeeze(0),\n",
    "            \"num_metadata\": torch.tensor(num_metadata).float(),\n",
    "            \"one_hot_metadata\": torch.cat(one_hot_metadata, dim=0).float(),\n",
    "            \"label\": torch.tensor(label),\n",
    "            \"example_id\": index\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac266f37-607b-4e14-91fd-6ddba2eeb34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LiarPlusSingleFinetunedRoBERTasClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self, encoder_model, num_metadata_len, one_hot_metadata_size, num_hidden, num_classes\n",
    "    ):\n",
    "        super(LiarPlusSingleFinetunedRoBERTasClassifier, self).__init__()\n",
    "        self.encoder = encoder_model\n",
    "        self.hl = nn.Linear(\n",
    "            self.encoder.config.hidden_size + num_metadata_len + one_hot_metadata_size, num_hidden\n",
    "        )\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.fc = nn.Linear(num_hidden, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, num_metadata, one_hot_metadata):\n",
    "        outputs = self.encoder(\n",
    "            input_ids=input_ids, attention_mask=attention_mask\n",
    "        )\n",
    "\n",
    "        cls_embedding = outputs.pooler_output\n",
    "        concatted_inputs = torch.cat([cls_embedding, num_metadata, one_hot_metadata], dim=1)\n",
    "\n",
    "        hl_output = F.gelu(self.hl(concatted_inputs))\n",
    "        hl_output = self.dropout(hl_output)\n",
    "\n",
    "        logits = self.fc(hl_output)\n",
    "        return logits\n",
    "\n",
    "    def roberta_trainable_state(self):\n",
    "        return {\n",
    "            name: param for name, param in self.encoder.named_parameters() if param.requires_grad\n",
    "        }\n",
    "    \n",
    "    def load_roberta_trainable_state(self, state_dict):\n",
    "        self.encoder.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "    # Zapisz tylko wagi warstw klasyfikatora\n",
    "    def state_for_save(self):\n",
    "        return {\n",
    "            'hl_state_dict': self.hl.state_dict(),\n",
    "            'fc_state_dict': self.fc.state_dict(),\n",
    "            'roberta_trainable': self.roberta_trainable_state(),\n",
    "        }\n",
    "        \n",
    "    # Ładowanie modelu (tylko wagi klasyfikatora)\n",
    "    def load_state_from_save(self, state):\n",
    "        self.hl.load_state_dict(state['hl_state_dict'])\n",
    "        self.fc.load_state_dict(state['fc_state_dict'])\n",
    "        if 'roberta_trainable' in state:\n",
    "            self.load_roberta_trainable_state(state['roberta_trainable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "992dc4de-c378-485e-8f9f-a61de08f6f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_classes = 6\n",
    "hidden_size = 128\n",
    "batch_size = 64\n",
    "\n",
    "text_columns = [\n",
    "    \"subject\",\n",
    "    \"speaker\",\n",
    "    \"job_title\",\n",
    "    \"state\",\n",
    "    \"party_affiliation\",\n",
    "    \"context\"\n",
    "]\n",
    "num_metadata_cols = [\n",
    "    \"barely_true_counts\",\n",
    "    \"false_counts\",\n",
    "    \"half_true_counts\",\n",
    "    \"mostly_true_counts\",\n",
    "    \"pants_on_fire_counts\",\n",
    "    \"grammar_errors\",\n",
    "    \"ratio_of_capital_letters\"\n",
    "]\n",
    "one_hot_cols = [\n",
    "    \"sentiment\",\n",
    "    \"question\",\n",
    "    \"curse\",\n",
    "    \"emotion\",\n",
    "    \"gibberish\",\n",
    "    \"offensiveness\",\n",
    "    \"political_bias\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "242a370d-86a9-4074-bbdc-c503bbf6d373",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "roberta = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# trenuje 2 ostatnie warstwy\n",
    "for name, param in roberta.named_parameters():\n",
    "    if name.startswith(\"encoder.layer.11\") or name.startswith(\"pooler\"):\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fd8457c-4414-494c-983d-76ad5c0ea9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = LiarPlusSingleRobertaDataset_SM_And_SMA(\n",
    "    \"data/normalized/test2.csv\",\n",
    "    tokenizer,\n",
    "    text_columns,\n",
    "    num_metadata_cols,\n",
    "    one_hot_cols\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_data, batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f032f827-6c35-4dad-91bf-8a3e8c9fe577",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "modelSMA = LiarPlusSingleFinetunedRoBERTasClassifier(\n",
    "    roberta,\n",
    "    len(num_metadata_cols),\n",
    "    one_hot_metadata_size,\n",
    "    hidden_size,\n",
    "    num_classes,\n",
    ").to(device)\n",
    "\n",
    "modelSM = LiarPlusSingleFinetunedRoBERTasClassifier(\n",
    "    roberta,\n",
    "    len(num_metadata_cols),\n",
    "    one_hot_metadata_size,\n",
    "    hidden_size,\n",
    "    num_classes,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51f8920e-c9f5-4de1-ace1-5bb12c37a0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Studia\\nauka\\Sztuczna Inteligencja\\praca inżynierska\\klasyfikator\\utils.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model = torch.load(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from best model checkpoint.\n",
      "Model loaded from best model checkpoint.\n"
     ]
    }
   ],
   "source": [
    "best_model_path = \"results/FinalSM/best_model_6.pth\"\n",
    "load_best_model(modelSM, best_model_path)\n",
    "\n",
    "best_model_path = \"results/FinalSMA/best_model_6.pth\"\n",
    "load_best_model(modelSMA, best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a58101-73bd-46a1-9d7e-2df859bd119c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|                                                                               | 0/21 [00:00<?, ?it/s]E:\\anaconda3\\envs\\ML\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:370: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "Evaluating:  90%|███████████████████████████████████████████████████████████████▎      | 19/21 [01:13<00:07,  3.87s/it]"
     ]
    }
   ],
   "source": [
    "example_ids = []\n",
    "all_SM_preds = []\n",
    "all_SMA_preds = []\n",
    "all_SM_probs = []\n",
    "all_SMA_probs = []\n",
    "all_labels = []\n",
    "\n",
    "modelSM.eval()\n",
    "modelSMA.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n",
    "        example_id = batch[\"example_id\"]\n",
    "        input_ids_SM = batch[\"input_ids_SM\"].to(device)\n",
    "        attention_mask_SM = batch[\"attention_mask_SM\"].to(device)\n",
    "        input_ids_SMA = batch[\"input_ids_SMA\"].to(device)\n",
    "        attention_mask_SMA = batch[\"attention_mask_SMA\"].to(device)\n",
    "        num_metadata = batch[\"num_metadata\"].to(device)\n",
    "        one_hot_metadata = batch[\"one_hot_metadata\"].to(device)\n",
    "        labels = batch[\"label\"]\n",
    "\n",
    "        outputs_SM = F.softmax(modelSM(input_ids_SM, attention_mask_SM, num_metadata, one_hot_metadata), dim=1)\n",
    "        outputs_SMA = F.softmax(modelSMA(input_ids_SMA, attention_mask_SMA, num_metadata, one_hot_metadata), dim=1)\n",
    "\n",
    "        preds_SM = torch.argmax(outputs_SM, dim=1)\n",
    "        preds_SMA = torch.argmax(outputs_SMA, dim=1)\n",
    "\n",
    "        example_ids += example_id.tolist()\n",
    "        all_SM_preds += preds_SM.tolist()\n",
    "        all_SMA_preds += preds_SMA.tolist()\n",
    "        all_SM_probs += outputs_SM.tolist()\n",
    "        all_SMA_probs += outputs_SMA.tolist()\n",
    "        all_labels += labels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47c7139-ee84-42ae-a4a3-047719a8de97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/test2.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1d8aa0-13f4-4ee1-9e83-954079339025",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SM_pred'] = all_SM_preds\n",
    "df['SMA_pred'] = all_SMA_preds\n",
    "df['SM_prob'] = all_SM_probs\n",
    "df['SMA_prob'] = all_SMA_probs\n",
    "df['label_num'] = all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa091ea1-ee8e-47e9-a446-cc64658631af",
   "metadata": {},
   "outputs": [],
   "source": [
    "SM_highest_prob = []\n",
    "SMA_highest_prob = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    SM_highest_prob.append(row['SM_prob'][row['SM_pred']])\n",
    "    SMA_highest_prob.append(row['SMA_prob'][row['SMA_pred']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e991184-231e-4064-9490-fc6f3f115dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SM_highest_prob'] = SM_highest_prob\n",
    "df['SMA_highest_prob'] = SMA_highest_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e9a928-a529-4192-8aa0-87bedce78b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('sm_vs_sma_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d158d49-2c5e-4be4-9768-b0cc219341aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c63696f-d92a-4ec8-a803-1f8b03c102f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['SM_highest_prob', 'SMA_highest_prob']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f2de7b-b6c4-48dc-9ab6-a67c56a38df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = df[(df['SM_pred'] != df['label_num']) & (df['SMA_pred'] == df['label_num'])].sort_values(['SM_highest_prob', 'SMA_highest_prob'], ascending=False).head(10)\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84b7ac1-0cb6-4d73-adda-8a9c82159217",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = df[(df['SM_pred'] == df['label_num']) & (df['SMA_pred'] != df['label_num'])].sort_values(['SM_highest_prob', 'SMA_highest_prob'], ascending=False).head(10)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c366115a-ffd5-4a71-a05f-32f4a9a4053d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

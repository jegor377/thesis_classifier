{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cab9198-0355-46cc-977e-2c61600d8a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from random import sample\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "from sklearn.utils import resample\n",
    "from torchmetrics.classification import (\n",
    "    MulticlassF1Score,\n",
    "    MulticlassPrecision,\n",
    "    MulticlassRecall,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import mlflow\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import paramiko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cfc9776-4c71-4969-9031-8e1423867d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import paramiko  # type: ignore\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "LABEL_MAPPING = {\n",
    "    \"pants-fire\": 0,\n",
    "    \"false\": 1,\n",
    "    \"barely-true\": 2,\n",
    "    \"half-true\": 3,\n",
    "    \"mostly-true\": 4,\n",
    "    \"true\": 5,\n",
    "}\n",
    "\n",
    "ids2labels = [\n",
    "    \"pants-fire\",\n",
    "    \"false\",\n",
    "    \"barely-true\",\n",
    "    \"half-true\",\n",
    "    \"mostly-true\",\n",
    "    \"true\",\n",
    "]\n",
    "\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, val_acc, path=\"checkpoint.pth\"):\n",
    "    checkpoint = {\n",
    "        \"model_state_dict\": model.state_for_save(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"epoch\": epoch,\n",
    "        \"val_acc\": val_acc,\n",
    "    }\n",
    "    torch.save(checkpoint, path)\n",
    "    print(\n",
    "        f\"Checkpoint saved at epoch {epoch} \"\n",
    "        f\"with validation accuracy {val_acc:.4f}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def load_checkpoint(\n",
    "    model, optimizer, path=\"checkpoint.pth\", resume=False, reset_epoch=False\n",
    "):\n",
    "    if not resume:\n",
    "        print(\"Resume is False. Starting from scratch.\")\n",
    "        return 0, 0  # Start fresh\n",
    "\n",
    "    if os.path.exists(path):\n",
    "        checkpoint = torch.load(path)\n",
    "        model.load_state_from_save(checkpoint[\"model_state_dict\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        epoch = checkpoint[\"epoch\"]\n",
    "        val_acc = checkpoint[\"val_acc\"]\n",
    "        if reset_epoch:\n",
    "            print(\n",
    "                f\"Checkpoint loaded: Starting from initial\"\n",
    "                f\"epoch, validation accuracy {val_acc:.4f}\"\n",
    "            )\n",
    "            return 0, val_acc  # Start fresh with existing model\n",
    "        else:\n",
    "            print(\n",
    "                f\"Checkpoint loaded: Resuming from epoch \"\n",
    "                f\"{epoch+1}, validation accuracy {val_acc:.4f}\"\n",
    "            )\n",
    "            return epoch + 1, val_acc  # Next epoch to train\n",
    "    else:\n",
    "        print(\"No checkpoint found. Starting from scratch.\")\n",
    "        return 0, 0  # Start fresh\n",
    "\n",
    "\n",
    "def save_best_model(model, optimizer, epoch, val_acc, path=\"best_model.pth\"):\n",
    "    best_model = {\n",
    "        \"model_state_dict\": model.state_for_save(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"epoch\": epoch,\n",
    "        \"val_acc\": val_acc,\n",
    "    }\n",
    "    torch.save(best_model, path)\n",
    "    print(\n",
    "        f\"Best model saved at epoch {epoch} \"\n",
    "        f\"with validation accuracy {val_acc:.4f}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def load_best_model(model, path=\"best_model.pth\"):\n",
    "    if os.path.exists(path):\n",
    "        best_model = torch.load(path)\n",
    "        model.load_state_from_save(best_model[\"model_state_dict\"])\n",
    "        print(\"Model loaded from best model checkpoint.\")\n",
    "    else:\n",
    "        print(\"No best model checkpoint found.\")\n",
    "\n",
    "\n",
    "def save_model_remotely(local_path, remote_path, creds):\n",
    "    # Ustawienia SSH\n",
    "    hostname = creds[\"hostname\"]\n",
    "    port = creds[\"port\"]\n",
    "    username = creds[\"username\"]\n",
    "    password = creds[\"password\"]\n",
    "\n",
    "    # Połączenie SSH\n",
    "    try:\n",
    "        ssh = paramiko.SSHClient()\n",
    "        ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "        ssh.connect(hostname, port=port, username=username, password=password)\n",
    "\n",
    "        # Pobierz rozmiar pliku lokalnego\n",
    "        file_size = os.path.getsize(local_path)\n",
    "\n",
    "        # Funkcja do aktualizacji paska postępu\n",
    "        def progress_callback(transferred, total):\n",
    "            progress_bar.update(transferred - progress_bar.n)\n",
    "\n",
    "        # Inicjalizuj pasek postępu\n",
    "        progress_bar = tqdm(\n",
    "            total=file_size,\n",
    "            unit=\"B\",\n",
    "            unit_scale=True,\n",
    "            desc=f\"Uploading {local_path}\",\n",
    "        )\n",
    "\n",
    "        # SFTP transfer z callbackiem\n",
    "        with ssh.open_sftp() as sftp:\n",
    "            temp_remote_path = (\n",
    "                remote_path + os.path.basename(local_path) + \".tmp\"\n",
    "            )\n",
    "            final_remote_path = remote_path + os.path.basename(local_path)\n",
    "\n",
    "            sftp.put(local_path, temp_remote_path, callback=progress_callback)\n",
    "\n",
    "            try:\n",
    "                sftp.remove(final_remote_path)\n",
    "            except IOError:\n",
    "                # Plik nie istnieje – można ignorować\n",
    "                pass\n",
    "\n",
    "            sftp.rename(temp_remote_path, final_remote_path)\n",
    "\n",
    "        # Po zakończeniu\n",
    "        progress_bar.close()\n",
    "        print(f\"Plik {os.path.basename(local_path)} został wysłany.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "    finally:\n",
    "        # Zapewnia, że połączenie SSH zawsze zostanie zamknięte\n",
    "        ssh.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f18d4dd8-1c69-47ea-9d05-91785f635b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LiarPlusBaseRobertaDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        filepath: str,\n",
    "        tokenizer,\n",
    "        max_length: int = 512,\n",
    "    ):\n",
    "        self.df = pd.read_csv(filepath)\n",
    "        self.df[\"statement\"] = self.df[\"statement\"].astype(str)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df.index)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        statement = self.df.iloc[index][\"statement\"]\n",
    "        label_str = self.df.iloc[index][\"label\"]\n",
    "\n",
    "        encoded = self.tokenizer(\n",
    "            statement,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        label = LABEL_MAPPING[label_str]\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": encoded[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoded[\"attention_mask\"].squeeze(0),\n",
    "            \"label\": torch.tensor(label),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8c32663-7d73-4761-8882-efc5b0c42aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class LiarPlusBaseRoBERTasClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self, encoder_model, num_classes\n",
    "    ):\n",
    "        super(LiarPlusBaseRoBERTasClassifier, self).__init__()\n",
    "        self.encoder = encoder_model\n",
    "        self.fc = nn.Linear(self.encoder.config.hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        with torch.no_grad():\n",
    "            outputs = self.encoder(\n",
    "                input_ids=input_ids, attention_mask=attention_mask\n",
    "            )\n",
    "\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "        logits = self.fc(cls_embedding)\n",
    "        return logits\n",
    "\n",
    "    # Zapisz tylko wagi warstw klasyfikatora\n",
    "    def state_for_save(self):\n",
    "        return {\n",
    "            'fc_state_dict': self.fc.state_dict(),\n",
    "        }\n",
    "        \n",
    "    # Ładowanie modelu (tylko wagi klasyfikatora)\n",
    "    def load_state_from_save(self, state):\n",
    "        self.fc.load_state_dict(state['fc_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a527a9d2-2850-4b86-af80-8258cf43eb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "roberta = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "for param in roberta.parameters():\n",
    "    param.requires_grad = False  # Freeze all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48d047f8-8ae7-48ef-9959-d64ec3f21812",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = LiarPlusBaseRobertaDataset(\n",
    "    \"data/normalized/train2.csv\",\n",
    "    tokenizer\n",
    ")\n",
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    training_data, batch_size=batch_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb35021e-7be9-4889-b2b7-77d1160c8ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LiarPlusBaseRoBERTasClassifier(\n",
       "  (encoder): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 6\n",
    "model = LiarPlusBaseRoBERTasClassifier(\n",
    "    roberta,\n",
    "    num_classes,\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcb33ccb-b677-476e-aa7d-70dbcb18c647",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isan\\AppData\\Local\\Temp\\ipykernel_23508\\2240503973.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model = torch.load(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from best model checkpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                           | 0/161 [00:00<?, ?it/s]E:\\anaconda3\\envs\\ML\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:370: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "  0%|                                                                                                                                                                           | 0/161 [00:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-8.9492e-01,  1.0884e-01,  4.4853e-02,  3.1243e-01,  2.1663e-01,\n",
      "         -2.0351e-01],\n",
      "        [-5.7822e-01,  1.5024e-01, -1.4315e-01,  1.0387e-01,  3.3188e-01,\n",
      "         -1.0929e-01],\n",
      "        [-1.0152e+00, -8.1179e-03, -6.8929e-02,  4.0695e-01,  3.5767e-01,\n",
      "         -1.8672e-01],\n",
      "        [-7.5284e-01,  1.0135e-01, -2.3083e-01,  3.0743e-01,  2.3144e-01,\n",
      "          6.0803e-02],\n",
      "        [-5.3404e-01,  2.0390e-01, -6.4482e-02,  1.1892e-01,  4.5022e-02,\n",
      "         -2.2283e-02],\n",
      "        [-9.8042e-01,  1.5690e-01, -1.8976e-01,  2.8061e-01,  3.2305e-01,\n",
      "         -1.1606e-03],\n",
      "        [-8.4892e-01,  2.5314e-01,  9.3451e-02,  3.1589e-01,  1.4447e-01,\n",
      "         -3.6117e-01],\n",
      "        [-6.6785e-01,  2.5050e-01,  2.2881e-01,  2.2148e-01,  7.1997e-02,\n",
      "         -3.9809e-01],\n",
      "        [-1.0230e+00,  2.0469e-01, -1.1851e-01,  1.5587e-01,  3.6168e-01,\n",
      "         -2.3021e-03],\n",
      "        [-8.4438e-01,  3.1092e-02, -1.5821e-01,  5.1605e-01,  2.7108e-01,\n",
      "         -9.3113e-02],\n",
      "        [-1.0193e+00,  4.9156e-01,  2.7303e-01,  2.7127e-01,  5.4285e-02,\n",
      "         -4.6673e-01],\n",
      "        [-7.5651e-01,  2.7133e-01, -1.8897e-01,  2.0437e-01,  7.8001e-02,\n",
      "          5.5627e-02],\n",
      "        [-3.1671e-01,  3.5415e-01,  2.2951e-01,  2.2657e-01, -8.8703e-02,\n",
      "         -5.1328e-01],\n",
      "        [-1.1096e+00,  2.2036e-01, -3.3765e-01,  6.6647e-02,  4.4673e-01,\n",
      "          2.7703e-01],\n",
      "        [-7.8437e-01,  2.5349e-01, -7.9421e-02,  6.8218e-02,  2.2604e-01,\n",
      "          4.6675e-04],\n",
      "        [-9.2899e-01,  9.2818e-02, -1.9228e-01,  2.8877e-01,  3.4585e-01,\n",
      "          6.9131e-03],\n",
      "        [ 6.1579e-03,  2.8974e-01, -1.4598e-02,  5.9168e-02, -1.1034e-01,\n",
      "         -2.8899e-01],\n",
      "        [-1.2656e+00,  1.5415e-01, -3.6471e-02,  4.1501e-01,  4.1370e-01,\n",
      "         -1.8361e-01],\n",
      "        [-8.7667e-01,  1.5819e-01, -7.0469e-02,  3.1123e-01,  2.8564e-01,\n",
      "         -2.0431e-01],\n",
      "        [-9.8399e-01,  1.7995e-01,  1.0869e-01,  2.7581e-01,  2.6005e-01,\n",
      "         -2.1152e-01],\n",
      "        [-9.2883e-01,  1.6767e-01, -1.3804e-01,  2.6834e-01,  2.8097e-01,\n",
      "         -2.0826e-02],\n",
      "        [-1.1424e+00, -2.0425e-02, -2.2306e-01,  1.2804e-01,  5.2800e-01,\n",
      "          3.3787e-01],\n",
      "        [-7.1579e-01,  2.2190e-01, -1.2868e-01,  4.2523e-02,  2.3369e-01,\n",
      "          8.0986e-02],\n",
      "        [-7.3994e-01,  2.8848e-01,  6.1744e-02,  2.8877e-01,  1.0221e-01,\n",
      "         -3.5819e-01],\n",
      "        [-3.2972e-01,  2.6573e-01,  1.0854e-01,  2.3736e-01, -4.3108e-02,\n",
      "         -4.3046e-01],\n",
      "        [-6.0433e-01,  4.1965e-01,  8.3801e-02,  5.6269e-02,  8.1244e-02,\n",
      "         -3.5641e-01],\n",
      "        [-1.0576e+00,  1.3449e-01,  1.8229e-01,  2.0605e-01,  1.5300e-01,\n",
      "         -6.2429e-02],\n",
      "        [-6.8446e-01,  2.6023e-01,  1.0897e-01,  3.8950e-01,  1.2426e-01,\n",
      "         -4.3114e-01],\n",
      "        [-4.9597e-01,  2.6612e-01,  1.0198e-01,  3.9256e-01,  2.3430e-02,\n",
      "         -5.3688e-01],\n",
      "        [-4.0498e-01,  3.1188e-01,  6.1521e-02,  1.5537e-01, -6.9880e-02,\n",
      "         -1.7717e-01],\n",
      "        [-1.3986e-01,  2.0157e-01,  7.4124e-02,  1.7165e-01, -1.2255e-01,\n",
      "         -2.7473e-01],\n",
      "        [-1.0370e+00,  2.7313e-02, -2.5669e-01,  2.4463e-01,  4.4240e-01,\n",
      "          1.9330e-01],\n",
      "        [-1.1657e+00,  2.4522e-01,  1.2501e-01,  2.4754e-01,  2.3645e-01,\n",
      "         -1.5934e-01],\n",
      "        [-1.0584e+00,  6.0217e-02,  2.9484e-01,  3.1466e-01,  2.0304e-01,\n",
      "         -2.6140e-01],\n",
      "        [-9.2228e-01,  1.3813e-01,  6.3419e-03,  2.1075e-01,  1.9076e-01,\n",
      "         -2.7842e-02],\n",
      "        [-7.7608e-01,  5.7938e-02,  1.7765e-01,  3.5973e-01,  1.3194e-01,\n",
      "         -2.2783e-01],\n",
      "        [-7.9885e-01,  1.5760e-01,  1.7169e-01,  3.6905e-01,  1.7800e-01,\n",
      "         -4.5364e-01],\n",
      "        [-8.0261e-01,  2.9052e-01, -5.6968e-02,  3.9695e-01,  7.3366e-02,\n",
      "         -1.6737e-01],\n",
      "        [-9.7667e-01,  6.1660e-02, -1.0220e-02,  3.7519e-01,  2.8191e-01,\n",
      "         -1.4378e-01],\n",
      "        [-7.9555e-01,  2.8409e-01, -9.4091e-02,  2.7423e-01,  1.9731e-01,\n",
      "         -1.7822e-01],\n",
      "        [-5.3845e-01,  2.0001e-01,  3.4476e-02,  1.9040e-01,  3.3668e-02,\n",
      "         -1.6421e-01],\n",
      "        [-1.1210e+00,  2.4885e-02,  2.1462e-01,  3.6780e-01,  2.1189e-01,\n",
      "         -1.7013e-01],\n",
      "        [-8.2161e-01,  2.6396e-01,  1.6614e-01,  2.7604e-01,  1.0296e-01,\n",
      "         -3.5786e-01],\n",
      "        [-4.1460e-01,  3.5185e-01, -1.3056e-01, -8.7982e-02,  4.1132e-02,\n",
      "          2.5787e-02],\n",
      "        [-9.7758e-01,  1.8817e-01, -2.7801e-01,  2.9838e-01,  2.9411e-01,\n",
      "          1.6623e-01],\n",
      "        [-7.8810e-01,  3.5444e-01,  2.2991e-02, -6.2273e-02,  1.1073e-01,\n",
      "          1.0677e-02],\n",
      "        [-7.1181e-01,  1.9409e-01, -1.6406e-01,  1.9402e-01,  2.1783e-01,\n",
      "          3.2102e-03],\n",
      "        [-7.9644e-01,  3.9023e-02,  1.1749e-01,  3.8761e-01,  1.1017e-01,\n",
      "         -2.4511e-01],\n",
      "        [-1.3845e+00, -3.4270e-01, -3.0989e-01,  6.4894e-01,  6.7696e-01,\n",
      "          2.1074e-01],\n",
      "        [-9.8077e-01,  1.9867e-01, -1.1164e-01,  2.7985e-01,  2.8635e-01,\n",
      "         -4.0705e-02],\n",
      "        [-1.4884e+00,  2.2595e-01, -3.4491e-01,  2.7378e-01,  4.8179e-01,\n",
      "          3.0043e-01],\n",
      "        [-9.8696e-01,  4.0794e-01, -7.3404e-02,  2.6487e-01,  1.8649e-01,\n",
      "         -1.9794e-01],\n",
      "        [-9.7030e-01,  2.8129e-01,  1.3456e-01,  2.2819e-01,  2.2721e-01,\n",
      "         -3.3626e-01],\n",
      "        [-6.8581e-01,  1.7882e-01, -1.5964e-01,  3.0582e-01,  2.2853e-01,\n",
      "         -1.0833e-01],\n",
      "        [-1.0758e+00,  9.0568e-02, -1.0060e-01,  2.5066e-01,  4.0034e-01,\n",
      "         -9.9203e-03],\n",
      "        [-1.6355e-01,  4.0793e-01,  1.9132e-01,  1.7303e-01, -1.9363e-01,\n",
      "         -6.2665e-01],\n",
      "        [-3.3660e-01,  2.3119e-01,  2.2071e-02,  1.4100e-01,  3.8306e-02,\n",
      "         -3.4399e-01],\n",
      "        [-7.7878e-01,  2.6083e-01,  2.2556e-02,  1.2581e-01,  3.1620e-02,\n",
      "         -4.4233e-02],\n",
      "        [-5.9574e-01,  1.8101e-01,  2.3738e-01,  3.0071e-01, -1.6549e-02,\n",
      "         -4.0756e-01],\n",
      "        [-4.4696e-01,  3.0733e-01, -1.4029e-01,  1.0085e-01,  1.3581e-01,\n",
      "         -1.9050e-01],\n",
      "        [-6.2806e-01,  8.1569e-02,  1.2505e-02,  7.6638e-02,  1.7126e-01,\n",
      "         -1.3664e-01],\n",
      "        [-6.9420e-01,  2.4602e-01,  1.2632e-01,  3.3528e-01,  8.3587e-02,\n",
      "         -3.3860e-01],\n",
      "        [-1.1653e+00,  1.9088e-01, -2.9227e-01,  1.5721e-01,  3.6096e-01,\n",
      "          2.3897e-01],\n",
      "        [-3.4847e-01,  3.6728e-01,  1.5456e-01,  2.6220e-01, -8.3316e-02,\n",
      "         -4.6575e-01]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "load_best_model(model, 'results/Base/best_model_10.pth')\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        res = model(input_ids=batch['input_ids'].to(device), attention_mask=batch['attention_mask'].to(device))\n",
    "        if (res.argmax(dim=1) == 3).any():\n",
    "            print(res)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e49f0817-1f07-4aef-9af2-2b9d7c4ad312",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = torch.tensor([[-8.9492e-01,  1.0884e-01,  4.4853e-02,  3.1243e-01,  2.1663e-01,\n",
    "         -2.0351e-01],\n",
    "        [-5.7822e-01,  1.5024e-01, -1.4315e-01,  1.0387e-01,  3.3188e-01,\n",
    "         -1.0929e-01],\n",
    "        [-1.0152e+00, -8.1179e-03, -6.8929e-02,  4.0695e-01,  3.5767e-01,\n",
    "         -1.8672e-01],\n",
    "        [-7.5284e-01,  1.0135e-01, -2.3083e-01,  3.0743e-01,  2.3144e-01,\n",
    "          6.0803e-02],\n",
    "        [-5.3404e-01,  2.0390e-01, -6.4482e-02,  1.1892e-01,  4.5022e-02,\n",
    "         -2.2283e-02],\n",
    "        [-9.8042e-01,  1.5690e-01, -1.8976e-01,  2.8061e-01,  3.2305e-01,\n",
    "         -1.1606e-03],\n",
    "        [-8.4892e-01,  2.5314e-01,  9.3451e-02,  3.1589e-01,  1.4447e-01,\n",
    "         -3.6117e-01],\n",
    "        [-6.6785e-01,  2.5050e-01,  2.2881e-01,  2.2148e-01,  7.1997e-02,\n",
    "         -3.9809e-01],\n",
    "        [-1.0230e+00,  2.0469e-01, -1.1851e-01,  1.5587e-01,  3.6168e-01,\n",
    "         -2.3021e-03],\n",
    "        [-8.4438e-01,  3.1092e-02, -1.5821e-01,  5.1605e-01,  2.7108e-01,\n",
    "         -9.3113e-02],\n",
    "        [-1.0193e+00,  4.9156e-01,  2.7303e-01,  2.7127e-01,  5.4285e-02,\n",
    "         -4.6673e-01],\n",
    "        [-7.5651e-01,  2.7133e-01, -1.8897e-01,  2.0437e-01,  7.8001e-02,\n",
    "          5.5627e-02],\n",
    "        [-3.1671e-01,  3.5415e-01,  2.2951e-01,  2.2657e-01, -8.8703e-02,\n",
    "         -5.1328e-01],\n",
    "        [-1.1096e+00,  2.2036e-01, -3.3765e-01,  6.6647e-02,  4.4673e-01,\n",
    "          2.7703e-01],\n",
    "        [-7.8437e-01,  2.5349e-01, -7.9421e-02,  6.8218e-02,  2.2604e-01,\n",
    "          4.6675e-04],\n",
    "        [-9.2899e-01,  9.2818e-02, -1.9228e-01,  2.8877e-01,  3.4585e-01,\n",
    "          6.9131e-03],\n",
    "        [ 6.1579e-03,  2.8974e-01, -1.4598e-02,  5.9168e-02, -1.1034e-01,\n",
    "         -2.8899e-01],\n",
    "        [-1.2656e+00,  1.5415e-01, -3.6471e-02,  4.1501e-01,  4.1370e-01,\n",
    "         -1.8361e-01],\n",
    "        [-8.7667e-01,  1.5819e-01, -7.0469e-02,  3.1123e-01,  2.8564e-01,\n",
    "         -2.0431e-01],\n",
    "        [-9.8399e-01,  1.7995e-01,  1.0869e-01,  2.7581e-01,  2.6005e-01,\n",
    "         -2.1152e-01],\n",
    "        [-9.2883e-01,  1.6767e-01, -1.3804e-01,  2.6834e-01,  2.8097e-01,\n",
    "         -2.0826e-02],\n",
    "        [-1.1424e+00, -2.0425e-02, -2.2306e-01,  1.2804e-01,  5.2800e-01,\n",
    "          3.3787e-01],\n",
    "        [-7.1579e-01,  2.2190e-01, -1.2868e-01,  4.2523e-02,  2.3369e-01,\n",
    "          8.0986e-02],\n",
    "        [-7.3994e-01,  2.8848e-01,  6.1744e-02,  2.8877e-01,  1.0221e-01,\n",
    "         -3.5819e-01],\n",
    "        [-3.2972e-01,  2.6573e-01,  1.0854e-01,  2.3736e-01, -4.3108e-02,\n",
    "         -4.3046e-01],\n",
    "        [-6.0433e-01,  4.1965e-01,  8.3801e-02,  5.6269e-02,  8.1244e-02,\n",
    "         -3.5641e-01],\n",
    "        [-1.0576e+00,  1.3449e-01,  1.8229e-01,  2.0605e-01,  1.5300e-01,\n",
    "         -6.2429e-02],\n",
    "        [-6.8446e-01,  2.6023e-01,  1.0897e-01,  3.8950e-01,  1.2426e-01,\n",
    "         -4.3114e-01],\n",
    "        [-4.9597e-01,  2.6612e-01,  1.0198e-01,  3.9256e-01,  2.3430e-02,\n",
    "         -5.3688e-01],\n",
    "        [-4.0498e-01,  3.1188e-01,  6.1521e-02,  1.5537e-01, -6.9880e-02,\n",
    "         -1.7717e-01],\n",
    "        [-1.3986e-01,  2.0157e-01,  7.4124e-02,  1.7165e-01, -1.2255e-01,\n",
    "         -2.7473e-01],\n",
    "        [-1.0370e+00,  2.7313e-02, -2.5669e-01,  2.4463e-01,  4.4240e-01,\n",
    "          1.9330e-01],\n",
    "        [-1.1657e+00,  2.4522e-01,  1.2501e-01,  2.4754e-01,  2.3645e-01,\n",
    "         -1.5934e-01],\n",
    "        [-1.0584e+00,  6.0217e-02,  2.9484e-01,  3.1466e-01,  2.0304e-01,\n",
    "         -2.6140e-01],\n",
    "        [-9.2228e-01,  1.3813e-01,  6.3419e-03,  2.1075e-01,  1.9076e-01,\n",
    "         -2.7842e-02],\n",
    "        [-7.7608e-01,  5.7938e-02,  1.7765e-01,  3.5973e-01,  1.3194e-01,\n",
    "         -2.2783e-01],\n",
    "        [-7.9885e-01,  1.5760e-01,  1.7169e-01,  3.6905e-01,  1.7800e-01,\n",
    "         -4.5364e-01],\n",
    "        [-8.0261e-01,  2.9052e-01, -5.6968e-02,  3.9695e-01,  7.3366e-02,\n",
    "         -1.6737e-01],\n",
    "        [-9.7667e-01,  6.1660e-02, -1.0220e-02,  3.7519e-01,  2.8191e-01,\n",
    "         -1.4378e-01],\n",
    "        [-7.9555e-01,  2.8409e-01, -9.4091e-02,  2.7423e-01,  1.9731e-01,\n",
    "         -1.7822e-01],\n",
    "        [-5.3845e-01,  2.0001e-01,  3.4476e-02,  1.9040e-01,  3.3668e-02,\n",
    "         -1.6421e-01],\n",
    "        [-1.1210e+00,  2.4885e-02,  2.1462e-01,  3.6780e-01,  2.1189e-01,\n",
    "         -1.7013e-01],\n",
    "        [-8.2161e-01,  2.6396e-01,  1.6614e-01,  2.7604e-01,  1.0296e-01,\n",
    "         -3.5786e-01],\n",
    "        [-4.1460e-01,  3.5185e-01, -1.3056e-01, -8.7982e-02,  4.1132e-02,\n",
    "          2.5787e-02],\n",
    "        [-9.7758e-01,  1.8817e-01, -2.7801e-01,  2.9838e-01,  2.9411e-01,\n",
    "          1.6623e-01],\n",
    "        [-7.8810e-01,  3.5444e-01,  2.2991e-02, -6.2273e-02,  1.1073e-01,\n",
    "          1.0677e-02],\n",
    "        [-7.1181e-01,  1.9409e-01, -1.6406e-01,  1.9402e-01,  2.1783e-01,\n",
    "          3.2102e-03],\n",
    "        [-7.9644e-01,  3.9023e-02,  1.1749e-01,  3.8761e-01,  1.1017e-01,\n",
    "         -2.4511e-01],\n",
    "        [-1.3845e+00, -3.4270e-01, -3.0989e-01,  6.4894e-01,  6.7696e-01,\n",
    "          2.1074e-01],\n",
    "        [-9.8077e-01,  1.9867e-01, -1.1164e-01,  2.7985e-01,  2.8635e-01,\n",
    "         -4.0705e-02],\n",
    "        [-1.4884e+00,  2.2595e-01, -3.4491e-01,  2.7378e-01,  4.8179e-01,\n",
    "          3.0043e-01],\n",
    "        [-9.8696e-01,  4.0794e-01, -7.3404e-02,  2.6487e-01,  1.8649e-01,\n",
    "         -1.9794e-01],\n",
    "        [-9.7030e-01,  2.8129e-01,  1.3456e-01,  2.2819e-01,  2.2721e-01,\n",
    "         -3.3626e-01],\n",
    "        [-6.8581e-01,  1.7882e-01, -1.5964e-01,  3.0582e-01,  2.2853e-01,\n",
    "         -1.0833e-01],\n",
    "        [-1.0758e+00,  9.0568e-02, -1.0060e-01,  2.5066e-01,  4.0034e-01,\n",
    "         -9.9203e-03],\n",
    "        [-1.6355e-01,  4.0793e-01,  1.9132e-01,  1.7303e-01, -1.9363e-01,\n",
    "         -6.2665e-01],\n",
    "        [-3.3660e-01,  2.3119e-01,  2.2071e-02,  1.4100e-01,  3.8306e-02,\n",
    "         -3.4399e-01],\n",
    "        [-7.7878e-01,  2.6083e-01,  2.2556e-02,  1.2581e-01,  3.1620e-02,\n",
    "         -4.4233e-02],\n",
    "        [-5.9574e-01,  1.8101e-01,  2.3738e-01,  3.0071e-01, -1.6549e-02,\n",
    "         -4.0756e-01],\n",
    "        [-4.4696e-01,  3.0733e-01, -1.4029e-01,  1.0085e-01,  1.3581e-01,\n",
    "         -1.9050e-01],\n",
    "        [-6.2806e-01,  8.1569e-02,  1.2505e-02,  7.6638e-02,  1.7126e-01,\n",
    "         -1.3664e-01],\n",
    "        [-6.9420e-01,  2.4602e-01,  1.2632e-01,  3.3528e-01,  8.3587e-02,\n",
    "         -3.3860e-01],\n",
    "        [-1.1653e+00,  1.9088e-01, -2.9227e-01,  1.5721e-01,  3.6096e-01,\n",
    "          2.3897e-01],\n",
    "        [-3.4847e-01,  3.6728e-01,  1.5456e-01,  2.6220e-01, -8.3316e-02,\n",
    "         -4.6575e-01]], device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48af6ccf-4910-407f-a03b-1f3596ee78c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 3, 3, 1, 4, 3, 1, 4, 3, 1, 1, 1, 4, 1, 4, 1, 3, 3, 3, 4, 4, 4, 3,\n",
       "        1, 1, 3, 3, 3, 1, 1, 4, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 1, 3, 1, 4, 3,\n",
       "        4, 4, 4, 1, 1, 3, 4, 1, 1, 1, 3, 1, 4, 3, 4, 1], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dc7b3ab-b6cc-4094-887b-49ad4fa659d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.8949,  0.1088,  0.0449,  0.3124,  0.2166, -0.2035], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4df6b0-4a4e-4c59-bcfb-6a8d6f6b3870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6e32dd9-e5a8-485d-ab4b-20b0a2e56b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "from torchmetrics.classification import (\n",
    "    MulticlassF1Score,\n",
    "    MulticlassPrecision,\n",
    "    MulticlassRecall,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b50d36a8-9ebf-4e4b-b54b-da67b414212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import (\n",
    "    LABEL_MAPPING,\n",
    "    ids2labels,\n",
    "    save_checkpoint,\n",
    "    load_checkpoint,\n",
    "    save_best_model,\n",
    "    load_best_model,\n",
    "    save_model_remotely\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aea68431-6093-42b2-8251-1b5e96ca8a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_labels = {\n",
    "    \"sentiment\": ['negative', 'neutral', 'positive'],\n",
    "\t\"question\": ['not_question', 'question'],\n",
    "\t\"curse\": ['curse', 'non-curse'],\n",
    "\t\"emotion\": ['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise'],\n",
    "\t\"gibberish\": ['clean', 'mild gibberish', 'word salad'],\n",
    "\t\"offensiveness\": ['non-offensive', 'offensive'],\n",
    "\t\"political_bias\": ['CENTER', 'LEFT', 'RIGHT']\n",
    "}\n",
    "\n",
    "label_to_index = {\n",
    "    \"sentiment\": {label: idx for idx, label in enumerate(one_hot_labels[\"sentiment\"])},\n",
    "\t\"question\": {label: idx for idx, label in enumerate(one_hot_labels[\"question\"])},\n",
    "\t\"curse\": {label: idx for idx, label in enumerate(one_hot_labels[\"curse\"])},\n",
    "\t\"emotion\": {label: idx for idx, label in enumerate(one_hot_labels[\"emotion\"])},\n",
    "\t\"gibberish\": {label: idx for idx, label in enumerate(one_hot_labels[\"gibberish\"])},\n",
    "\t\"offensiveness\": {label: idx for idx, label in enumerate(one_hot_labels[\"offensiveness\"])},\n",
    "\t\"political_bias\": {label: idx for idx, label in enumerate(one_hot_labels[\"political_bias\"])}\n",
    "}\n",
    "\n",
    "one_hot_metadata_size = sum([len(x) for x in one_hot_labels.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8f3da8b-e341-4693-9338-47d85801a526",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LiarPlusSingleRobertaDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        filepath: str,\n",
    "        tokenizer,\n",
    "        str_metadata_cols: list[str],\n",
    "        num_metadata_cols: list[str],\n",
    "#        one_hot_metadata_cols: list[str],\n",
    "        max_length: int = 512,\n",
    "    ):\n",
    "        self.df = pd.read_csv(filepath)\n",
    "\n",
    "        self.str_metadata_cols = str_metadata_cols\n",
    "        self.num_metadata_cols = num_metadata_cols\n",
    "        #self.one_hot_metadata_cols = one_hot_metadata_cols\n",
    "\n",
    "        for column in self.str_metadata_cols:\n",
    "            self.df[column] = self.df[column].astype(str)\n",
    "\n",
    "        self.df[\"statement\"] = self.df[\"statement\"].astype(str)\n",
    "        self.df[\"justification\"] = self.df[\"justification\"].astype(str)\n",
    "        self.df[\"articles\"] = self.df[\"articles\"].astype(str)\n",
    "\n",
    "        self.statement_max_len = max_length // 4\n",
    "        self.justification_max_len = max_length // 4\n",
    "        self.article_max_len = max_length // 4\n",
    "        self.str_metadata_max_len = max((\n",
    "            max_length - self.statement_max_len - self.justification_max_len - self.article_max_len\n",
    "        ) // len(str_metadata_cols), 15)\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df.index)\n",
    "        \n",
    "    def limit_tokens(self, text, max_length=512):\n",
    "        return self.tokenizer.convert_tokens_to_string(\n",
    "            self.tokenizer.tokenize(text)[:max_length]\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        item = self.df.iloc[index]\n",
    "\n",
    "        input_text = self.limit_tokens(\n",
    "            f\"[STATEMENT] {item['statement']}\",\n",
    "            self.statement_max_len\n",
    "        )\n",
    "        input_text += self.limit_tokens(\n",
    "            f\" [JUSTIFICATION] {item['justification']}\",\n",
    "            self.justification_max_len,\n",
    "        )\n",
    "        input_text += self.limit_tokens(\n",
    "            f\" [ARTICLE] {item['articles']}\",\n",
    "            self.article_max_len,\n",
    "        )\n",
    "\n",
    "        for column in self.str_metadata_cols:\n",
    "            input_text += self.limit_tokens(f\" [{column.upper()}] {item[column]}\", self.str_metadata_max_len)\n",
    "\n",
    "        encoded = self.tokenizer(\n",
    "            input_text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        label = LABEL_MAPPING[item[\"label\"]]\n",
    "\n",
    "        num_metadata = [item[column] for column in self.num_metadata_cols]\n",
    "\n",
    "        #one_hot_metadata = []\n",
    "        #for column in self.one_hot_metadata_cols:\n",
    "        #    value = item[column]\n",
    "        #    possible_values = len(one_hot_labels[column])\n",
    "        #    id_tensor = torch.tensor(label_to_index[column][value])\n",
    "        #    one_hot_metadata.append(F.one_hot(id_tensor, possible_values))\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": encoded[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoded[\"attention_mask\"].squeeze(0),\n",
    "            \"num_metadata\": torch.tensor(num_metadata).float(),\n",
    "            #\"one_hot_metadata\": torch.cat(one_hot_metadata, dim=0).float(),\n",
    "            \"label\": torch.tensor(label),\n",
    "            \"input_text\": input_text\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac266f37-607b-4e14-91fd-6ddba2eeb34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LiarPlusSingleFinetunedRoBERTasClassifier(nn.Module):\n",
    "    #one_hot_metadata_size, \n",
    "    def __init__(\n",
    "        self, encoder_model, num_metadata_len, num_hidden, num_classes\n",
    "    ):\n",
    "        super(LiarPlusSingleFinetunedRoBERTasClassifier, self).__init__()\n",
    "        self.encoder = encoder_model\n",
    "        # + one_hot_metadata_size\n",
    "        self.hl = nn.Linear(\n",
    "            self.encoder.config.hidden_size + num_metadata_len, num_hidden\n",
    "        )\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.fc = nn.Linear(num_hidden, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, num_metadata):#, one_hot_metadata):\n",
    "        outputs = self.encoder(\n",
    "            input_ids=input_ids, attention_mask=attention_mask\n",
    "        )\n",
    "\n",
    "        cls_embedding = outputs.pooler_output\n",
    "        #, one_hot_metadata\n",
    "        concatted_inputs = torch.cat([cls_embedding, num_metadata], dim=1)\n",
    "\n",
    "        hl_output = F.gelu(self.hl(concatted_inputs))\n",
    "        hl_output = self.dropout(hl_output)\n",
    "\n",
    "        logits = self.fc(hl_output)\n",
    "        return logits\n",
    "\n",
    "    def roberta_trainable_state(self):\n",
    "        return {\n",
    "            name: param for name, param in self.encoder.named_parameters() if param.requires_grad\n",
    "        }\n",
    "    \n",
    "    def load_roberta_trainable_state(self, state_dict):\n",
    "        self.encoder.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "    # Zapisz tylko wagi warstw klasyfikatora\n",
    "    def state_for_save(self):\n",
    "        return {\n",
    "            'hl_state_dict': self.hl.state_dict(),\n",
    "            'fc_state_dict': self.fc.state_dict(),\n",
    "            'roberta_trainable': self.roberta_trainable_state(),\n",
    "        }\n",
    "        \n",
    "    # Ładowanie modelu (tylko wagi klasyfikatora)\n",
    "    def load_state_from_save(self, state):\n",
    "        self.hl.load_state_dict(state['hl_state_dict'])\n",
    "        self.fc.load_state_dict(state['fc_state_dict'])\n",
    "        if 'roberta_trainable' in state:\n",
    "            self.load_roberta_trainable_state(state['roberta_trainable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1918be92-86fa-40ec-ac25-f941a97140f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(\n",
    "    model: nn.Module,\n",
    "    best_model_path: str,\n",
    "    dataloader: DataLoader,\n",
    "    name: str='Test'\n",
    ") -> None:\n",
    "    # Define loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    load_best_model(model, best_model_path)\n",
    "\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    f1 = MulticlassF1Score(num_classes, average=None).to(device)\n",
    "    precision = MulticlassPrecision(num_classes, average=None).to(device)\n",
    "    recall = MulticlassRecall(num_classes, average=None).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            num_metadata = batch[\"num_metadata\"].to(device)\n",
    "            #one_hot_metadata = batch[\"one_hot_metadata\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask, num_metadata)#, one_hot_metadata)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * input_ids.size(0)\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            total_correct += (preds == labels).sum().item()\n",
    "            total_samples += input_ids.size(0)\n",
    "\n",
    "            f1.update(preds, labels)\n",
    "            precision.update(preds, labels)\n",
    "            recall.update(preds, labels)\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    accuracy = total_correct / total_samples\n",
    "\n",
    "    f1_res = f1.compute()\n",
    "    precision_res = precision.compute()\n",
    "    recall_res = recall.compute()\n",
    "\n",
    "    macro_f1 = f1_res.mean()\n",
    "    macro_precision = precision_res.mean()\n",
    "    macro_recall = recall_res.mean()\n",
    "\n",
    "    print(\n",
    "        f\"{name} Accuracy: {accuracy:.4f},\\n\"\n",
    "        f\"{name} Loss: {avg_loss:.4f},\\n\"\n",
    "        f\"{name} F1: {f1_res} (marcro = {macro_f1:.4f}),\\n\"\n",
    "        f\"{name} Precision: {precision_res} (marcro = {macro_precision:.4f}),\\n\"\n",
    "        f\"{name} Recall: {recall_res} (marcro = {macro_recall:.4f}),\\n\"\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        accuracy,\n",
    "        avg_loss,\n",
    "        macro_f1,\n",
    "        macro_precision,\n",
    "        macro_recall\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "992dc4de-c378-485e-8f9f-a61de08f6f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_classes = 6\n",
    "hidden_size = 128\n",
    "batch_size = 10\n",
    "\n",
    "text_columns = [\n",
    "    \"subject\",\n",
    "    \"speaker\",\n",
    "    \"job_title\",\n",
    "    \"state\",\n",
    "    \"party_affiliation\",\n",
    "    \"context\",\n",
    "    \"sentiment\",\n",
    "    \"question\",\n",
    "    \"curse\",\n",
    "    \"emotion\",\n",
    "    \"gibberish\",\n",
    "    \"offensiveness\",\n",
    "    \"political_bias\"\n",
    "]\n",
    "num_metadata_cols = [\n",
    "    \"barely_true_counts\",\n",
    "    \"false_counts\",\n",
    "    \"half_true_counts\",\n",
    "    \"mostly_true_counts\",\n",
    "    \"pants_on_fire_counts\",\n",
    "    \"grammar_errors\",\n",
    "    \"ratio_of_capital_letters\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "242a370d-86a9-4074-bbdc-c503bbf6d373",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "roberta = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# trenuje 2 ostatnie warstwy\n",
    "for name, param in roberta.named_parameters():\n",
    "    if name.startswith(\"encoder.layer.11\") or name.startswith(\"pooler\"):\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7fd8457c-4414-494c-983d-76ad5c0ea9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = LiarPlusSingleRobertaDataset(\n",
    "    \"data/normalized/val2.csv\",\n",
    "    tokenizer,\n",
    "    text_columns,\n",
    "    num_metadata_cols\n",
    ")\n",
    "test_data = LiarPlusSingleRobertaDataset(\n",
    "    \"data/normalized/test2.csv\",\n",
    "    tokenizer,\n",
    "    text_columns,\n",
    "    num_metadata_cols\n",
    ")\n",
    "\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    validation_data, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_data, batch_size=batch_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30285069-f730-44cb-9335-ba60715417ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATEMENT] Florida unemployment has dropped more than 2 percentage points, down from 12 percent to 9.9 percent, the second-largest drop in the nation. [JUSTIFICATION] And even with the 2. 1 percentage point decrease, Florida still has the fifth-highest unemployment rate in the country. [ARTICLE] The Florida sunshine has been a beacon for many job seekers in recent months as the state's unemployment rate plummeted. With a record-breaking drop of more than 2 percentage points, the state has seen its unemployment rate fall from a concerning 12 percent to a remarkable 9.9 percent, the second-largest decrease nationwide. This dramatic improvement showcases the success of Florida's ongoing economic recovery efforts and the strong performance of many businesses in the state. The recent success of Florida's workforce is a testament to the commitment of both businesses and residents alike. The state's unemployment rate has now stabilized at a healthier level, signifying a substantial [SUBJECT] economy,jobs [SPEAKER] rick-scott [JOB_TITLE] Governor [STATE] Florida [PARTY_AFFILIATION] republican [CONTEXT] a speech at the CPAC conference [SENTIMENT] neutral [QUESTION] not_question [CURSE] non-curse [EMOTION] neutral [GIBBERISH] clean [OFFENSIVENESS] non-offensive [POLITICAL_BIAS] CENTER \n",
      "\n",
      "[STATEMENT] Were borrowing 20% of (the federal) budget. [JUSTIFICATION] In 2014, Social Security rose by $37 billion (or 5 percent); Medicare increased $14 billion (or 3 percent); and Medicaid rose $36 billion (or 14 percent), largely because of the expansion of insurance coverage under the Affordable Care Act, the Congressional Budget Office reported. On the other hand, spending for unemployment benefits declined by $24 billion (or 33 percent) as fewer people received benefits after an emergency extension expired, CBO said. He was on target earlier this year with that figure based on 2013 results, but the latest numbers are just in for 2014 and show a decline from that 20 percent mark. [ARTICLE] The federal budget is a complex and evolving document, balancing the demands of government spending and revenue generation. A recent study reveals that the United States federal government has been borrowing 20% of its budget over the past five years. This revelation has sparked debate and concern within the political and financial landscapes. Many voices are raising questions about the implications of such high borrowing levels and their impact on the nation's long-term fiscal health. Some argue that this high borrowing is a symptom of systemic issues within the government and that it stems from an accumulation of unsustainable expenditure and lack of tax reform. Others point out that this borrowing could be a [SUBJECT] federal-budget [SPEAKER] glenn-grothman [JOB_TITLE] State Senator, 20th District [STATE] Wisconsin [PARTY_AFFILIATION] republican [CONTEXT] an interview [SENTIMENT] neutral [QUESTION] not_question [CURSE] non-curse [EMOTION] neutral [GIBBERISH] clean [OFFENSIVENESS] non-offensive [POLITICAL_BIAS] RIGHT \n",
      "\n",
      "[STATEMENT] The new Ukrainian government introduced a law abolishing the use of languages other than Ukrainian in official circumstances. [JUSTIFICATION] Russia Today said the Ukrainians introduced a law abolishing the use of any language except Ukrainian for official business. The Ukrainian parliament did vote to repeal a 2012 law that allowed for more official languages in parts of the country. But the repeal vote was not signed into law by the Ukraines interim president. Also, Crimea -- the center of the crisis currently in Ukraine -- has long held a special status whereby both Russian and Ukrainian could be used in official business. The recent vote would not have changed that, experts told us. We make no determination as to whether the parliaments move triggered a call for aid from officials in [ARTICLE] The recent developments in Ukraine have sparked widespread concern and international outrage. Just days after the new government took office, they have enacted a law that has fundamentally altered the cultural landscape. The law, formally dubbed \"The Law on the Use of the Ukrainian Language,\" has been met with strong criticism from human rights organizations, as well as from many across the world. This legislation effectively bans the use of any other language, such as Russian or English, in official government settings. This includes public institutions, educational facilities, and even media outlets. The law has come under heavy scrutiny due to its potential for infringing upon freedom of expression and [SUBJECT] foreign-policy [SPEAKER] russia-today [JOB_TITLE] nan [STATE] nan [PARTY_AFFILIATION] none [CONTEXT] a posting on their website [SENTIMENT] neutral [QUESTION] not_question [CURSE] non-curse [EMOTION] disgust [GIBBERISH] clean [OFFENSIVENESS] non-offensive [POLITICAL_BIAS] RIGHT \n",
      "\n",
      "[STATEMENT] Violent crime is up since the last year of Sharpe James administration. This year its higher. The unemployment rate is almost 15 percent. The high school dropout rate is over 50 percent. [JUSTIFICATION] Lonegan said, \"Violent crime is up since the last year of Sharpe James administration. The unemployment rate is almost 15 percent. The high school dropout rate is over 50 percent. \"Overall violent crime is up whether measured from 2005 or 2006 to 2012, but the increase is skewed by a sharp uptick in robberies, according to UCR statistics. Violent crime is down in other categories. Unemployment during Bookers tenure has hovered between 14 percent and 16 percent, but the impact of the recession on those figures cant be disregarded. There are other routes to graduation. [ARTICLE] The city is reeling from the alarming rise in violent crime, a trend that has continued unabated even during this year's tenure of Mayor James. While this trend initially seemed to ease after his inauguration, recent statistics have revealed a disturbing upward spiral in criminal activity, suggesting a growing crisis. The escalating violence is pushing families to the edge and creating an atmosphere of fear within our community. This unsettling reality is compounded by the city's devastating unemployment rate. As the number of unemployed individuals rises to nearly 15 percent, the economic burdens on citizens are becoming unbearable. The lack of opportunities for work pushes many into a desperate state, leading [SUBJECT] crime,education,jobs [SPEAKER] steve-lonegan [JOB_TITLE] Conservative Activist [STATE] New Jersey [PARTY_AFFILIATION] republican [CONTEXT] an interview on the John Gambling radio show [SENTIMENT] negative [QUESTION] not_question [CURSE] non-curse [EMOTION] anger [GIBBERISH] mild gibberish [OFFENSIVENESS] non-offensive [POLITICAL_BIAS] CENTER \n",
      "\n",
      "[STATEMENT] Limberbutt McCubbins (a five-year-old cat) is a candidate in the 2016 presidential election. [JUSTIFICATION] McCubbins, a five-year-old cat, said, \"Limberbutt McCubbins is a candidate\" in the 2016 presidential election. (Though we have fact-checked a terrier who supported Mitt Romney in 2008. )Limberbutts campaign manager has filed official paperwork, but the FEC doesnt deem him formally a candidate, because he hasnt spent or received $5,000. (This is also the case for some human candidates. )Experts told us its very unlikely that hell appear on any ballots as a candidate, and its even more unlikely that his candidacy will stand in a court [ARTICLE] The race for the 2016 presidential election has become one of the most unexpected and peculiar events in recent political history. While most political analysts are preoccupied with seasoned politicians and their promises, a five-year-old cat named Limberbutt McCubbins is challenging the status quo. McCubbins, an unusually articulate feline with a distinguished past and numerous policy proposals, has gained a surprising following within the polls. His campaign slogan, \"Purrfect Peace,\" resonates with a large portion of the voting population yearning for a more peaceful and, perhaps, more comfortable world. McCubbins himself insists he lacks [SUBJECT] animals,corrections-and-updates, [SPEAKER] limberbutt-mccubbins [JOB_TITLE] nan [STATE] nan [PARTY_AFFILIATION] democrat [CONTEXT] comments on his website. [SENTIMENT] neutral [QUESTION] not_question [CURSE] non-curse [EMOTION] neutral [GIBBERISH] clean [OFFENSIVENESS] non-offensive [POLITICAL_BIAS] RIGHT \n",
      "\n",
      "[STATEMENT] Says the Texas Board of Nursing has a backlog of 3,000 complaints against nurses, many of them sexual assaults, malfeasance. [JUSTIFICATION] He offered several examples: The investigator may be under-performing; extensive due process is required; the medical records of the patient involved in the complaint are difficult to obtain. So, the board says it has about 3,000 backlogged complaints, as Whitmire said. According to the board, many of the complaints allege malfeasance by nurses, as Whitmire also said, and a smaller number involve sexual assaults. But no one can determine the precise breakout without access to confidential board information. [ARTICLE] The Texas Board of Nursing is facing accusations of a staggering backlog of 3,000 complaints against nurses, with a significant number of them related to serious allegations of sexual assault and malfeasance. This revelation comes amidst a growing public outcry for transparency and accountability within the state's healthcare system.  The Texas Board of Nursing, responsible for regulating and licensing nurses, has been increasingly scrutinized for its handling of complaints and allegations of misconduct.  The massive backlog paints a stark picture of the potential for a systemic failure in identifying, investigating, and resolving these critical issues. This situation raises critical questions about the state's commitment to protecting [SUBJECT] crime,health-care,market-regulation [SPEAKER] john-whitmire [JOB_TITLE] Texas state senator [STATE] Texas [PARTY_AFFILIATION] democrat [CONTEXT] remarks on the Senate floor [SENTIMENT] negative [QUESTION] not_question [CURSE] non-curse [EMOTION] neutral [GIBBERISH] clean [OFFENSIVENESS] non-offensive [POLITICAL_BIAS] CENTER \n",
      "\n",
      "[STATEMENT] The average federal employee makes $120,000 a year. The average private employee makes $60,000 a year. [JUSTIFICATION] Paul said that the \"average federal employee makes $120,000 a year. The average private employee makes $60,000 a year. \"Most people hearing that would assume he was talking about salary alone, but he was talking about total compensation, including benefits such as retirement pay and paid holidays. Although studies show federal employees typically earn more than their private-sector counterparts, the difference is nowhere near as much as the doubling Paul says. [ARTICLE] The stark reality of the American economic landscape becomes even clearer when we compare the average income of federal employees with that of private employees. The average federal employee earns a generous $120,000 per year, significantly surpassing the average private employee's income of $60,000. While the financial disparities within the workforce are a complex issue, it's undeniably true that federal employees often enjoy a much higher income, leaving many private employees grappling with the challenging reality of affordability in the face of rapidly increasing costs of living. This disparity in income levels is not just a statistic; it carries profound implications for the quality of life and economic [SUBJECT] economy,federal-budget,abc-news [SPEAKER] rand-paul [JOB_TITLE] Candidate for U.S. Senate and [STATE] Kentucky [PARTY_AFFILIATION] republican [CONTEXT] an interview on ABC's This Week with Christiane Aman [SENTIMENT] neutral [QUESTION] not_question [CURSE] non-curse [EMOTION] neutral [GIBBERISH] clean [OFFENSIVENESS] non-offensive [POLITICAL_BIAS] LEFT \n",
      "\n",
      "[STATEMENT] Says a Republican hasnt won [an election] for a presidency in New Jersey since 1988. [JUSTIFICATION] Christie said \"a Republican hasn't won [an election] for a presidency in New Jersey since 1988. \"When Bush took on Dukakis in 1988, a majority of New Jersey voters cast a ballot for the Republican candidate, helping send Bush to the White House. But four years later, the tide turned in New Jersey and the state has voted Democratic in every presidential election since. [ARTICLE] The history of Republican presidential candidates in New Jersey is a fascinating one. While other states have seen their fair share of GOP victories, New Jersey's landscape has remained stubbornly resistant to the Republican party at the national level. Since 1988, the last Republican to win the presidency of the state has been the man himself, former President George H. W. Bush.  The last time a Republican candidate secured the nomination for president from New Jersey was in 1988 when George H. W. Bush carried the state, becoming the only Republican to win a state election since 1988. It’s a phenomenon that's seen as a [SUBJECT] elections,states [SPEAKER] chris-christie [JOB_TITLE] Governor of New Jersey [STATE] New Jersey [PARTY_AFFILIATION] republican [CONTEXT] a news conference [SENTIMENT] negative [QUESTION] not_question [CURSE] non-curse [EMOTION] sadness [GIBBERISH] clean [OFFENSIVENESS] non-offensive [POLITICAL_BIAS] CENTER \n",
      "\n",
      "[STATEMENT] The Milwaukee County bus system has among the highest fares in the nation. [JUSTIFICATION] The highest fare -- in Nashville -- was $4 per ride. Our rating Larson said the Milwaukee County bus system has \"among the highest fares in the nation. \"But the systems $2. 25 cash fare wasnt at the top of a national comparison, with fares reaching as high as $4 per trip. And regular patrons who use a Smart Card are charged just $1. 75 a ride, making the Milwaukee County bus system about on par with average costs. [ARTICLE] The rising cost of bus rides in Milwaukee County has become a major talking point among residents and transit advocates. While many cities prioritize affordable public transportation options, Milwaukee County's bus system stands out as particularly expensive. Data from the Federal Transit Administration (FTA) reveals that the county's bus fares are among the highest in the nation, often surpassing even major cities like Seattle and Boston. This has led to concerns about accessibility, affordability, and the impact on people who rely on the system for essential travel and employment. A recent survey conducted by the Milwaukee Journal Sentinel found that 54% of respondents expressed dissatisfaction with the high fares [SUBJECT] transportation [SPEAKER] chris-larson [JOB_TITLE] Wisconsin Senate Minority Leader [STATE] Wisconsin [PARTY_AFFILIATION] democrat [CONTEXT] a TV interview [SENTIMENT] neutral [QUESTION] not_question [CURSE] non-curse [EMOTION] neutral [GIBBERISH] clean [OFFENSIVENESS] non-offensive [POLITICAL_BIAS] RIGHT \n",
      "\n",
      "[STATEMENT] Under President Barack Obamas leadership, since June 2009, (the auto) industry has added a quarter of a million jobs. [JUSTIFICATION] The data will change once new jobs figures are released on Sept.  7, 2012. But at the time King made the statement, his data was correct. [ARTICLE] The automotive industry has seen a remarkable resurgence under President Barack Obama's leadership. Since June 2009, the sector has added an astounding 250,000 jobs, marking a significant turnaround from the bleak economic landscape of the previous decade. This positive trend reflects a broader national economic growth, fueled by aggressive government policies and private sector investments. The government's economic stimulus programs, aimed at boosting demand and revitalizing the economy, have played a crucial role in this resurgence. By investing in infrastructure projects and providing tax incentives for domestic manufacturers, the government has incentivized companies to expand and create new jobs. Moreover, the administration's commitment to promoting [SUBJECT] jobs [SPEAKER] bob-king [JOB_TITLE] President of the UAW [STATE] Michigan [PARTY_AFFILIATION] none [CONTEXT] a speech to the Democratic National Convention in Charlotte, N [SENTIMENT] positive [QUESTION] not_question [CURSE] non-curse [EMOTION] neutral [GIBBERISH] clean [OFFENSIVENESS] non-offensive [POLITICAL_BIAS] RIGHT \n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(val_dataloader))\n",
    "for row in batch[\"input_text\"]:\n",
    "    print(row, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8e2638-8fc6-4a44-a511-939cb7852cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
